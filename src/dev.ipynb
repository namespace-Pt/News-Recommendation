{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from utils.manager import Manager\n",
    "from utils.util import load_pickle, save_pickle, BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 10:48:15,077] INFO (Manager) Hyper Parameters are:\n",
      "{'scale': 'demo', 'batch_size': 2, 'batch_size_eval': 2, 'checkpoint': 'none', 'verbose': None, 'his_size': 50, 'impr_size': 20, 'negative_num': 4, 'dropout_p': 0.1, 'learning_rate': 1e-05, 'scheduler': 'none', 'warmup': 0.1, 'title_length': 32, 'abs_length': 64, 'enable_fields': ['title', 'abs'], 'newsEncoder': 'cnn', 'userEncoder': 'rnn', 'hidden_dim': 768, 'head_num': 12, 'k': 4, 'plm': 'distilbert', 'seed': 3407, 'world_size': 1, 'sequence_length': 96}\n",
      "\n",
      "[2022-03-30 10:48:15,081] INFO (MIND_Train) Loading Cache at MINDdemo_train\n",
      "[2022-03-30 10:48:15,981] INFO (MIND_Dev) Loading Cache at MINDdemo_dev\n",
      "[2022-03-30 10:48:16,779] INFO (MIND_News) Loading Cache at MINDdemo_dev\n"
     ]
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "-bs 2 -bse 2 -ef title abs -s demo -plm distilbert\n",
    "\"\"\"\n",
    "manager = Manager(command=command.strip().split(\" \"))\n",
    "loaders = manager.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AutoTokenizer.from_pretrained(manager.plm_dir)\n",
    "m = AutoModel.from_pretrained(manager.plm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = loaders[\"train\"]\n",
    "loader_dev = loaders[\"dev\"]\n",
    "loader_news = loaders[\"news\"]\n",
    "\n",
    "dataset_train = loader_train.dataset\n",
    "dataset_dev = loader_dev.dataset\n",
    "dataset_news = loader_news.dataset\n",
    "\n",
    "X1 = iter(loader_train)\n",
    "X2 = iter(loader_dev)\n",
    "X3 = iter(loader_news)\n",
    "x = next(X1)\n",
    "x2 = next(X2)\n",
    "x3 = next(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the brands queen elizabeth, prince charles, and prince philip swear by shop the notebooks, jackets, and more that the royals can't live without.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check news\n",
    "index = 1\n",
    "cdd_token_id = x3['cdd_token_id'][index]\n",
    "t.decode(cdd_token_id, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (3) must match the existing size (2) at non-singleton dimension 1.  Target sizes: [2, 3, 3].  Tensor sizes: [2, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m a\u001b[39m.\u001b[39;49mexpand(\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m3\u001b[39;49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (3) must match the existing size (2) at non-singleton dimension 1.  Target sizes: [2, 3, 3].  Tensor sizes: [2, 3]"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,3)\n",
    "a.expand(2,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     a \n",
      "[CLS]                1\n",
      "what                 1\n",
      "you                  1\n",
      "need                 1\n",
      "to                   1\n",
      "know                 1\n",
      "about                1\n",
      "the                  1\n",
      "c                    1\n",
      "##8                  1\n",
      "corvette             1\n",
      "'                    1\n",
      "s                    1\n",
      "new                  1\n",
      "dual                 1\n",
      "-                    1\n",
      "clutch               1\n",
      "transmission         1\n",
      "[SEP]                1\n",
      "the                  1\n",
      "new                  1\n",
      "corvette             1\n",
      "has                  1\n",
      "an                   1\n",
      "eight                1\n",
      "-                    1\n",
      "speed                1\n",
      "tre                  1\n",
      "##me                 1\n",
      "##c                  1\n",
      "dc                   1\n",
      "##t                  1\n",
      ".                    1\n",
      "we                   1\n",
      "weren                1\n",
      "'                    1\n",
      "t                    1\n",
      "crazy                1\n",
      "about                1\n",
      "it                   1\n",
      "in                   1\n",
      "the                  1\n",
      "pre                  1\n",
      "-                    1\n",
      "production           1\n",
      "c                    1\n",
      "##8                  1\n",
      "we                   1\n",
      "drove                1\n",
      ",                    1\n",
      "but                  1\n",
      "engineers            1\n",
      "tell                 1\n",
      "us                   1\n",
      "the                  1\n",
      "final                1\n",
      "version              1\n",
      "will                 1\n",
      "be                   1\n",
      "better               1\n",
      ".                    1\n",
      "[SEP]                1\n",
      "[PAD]                0\n"
     ]
    }
   ],
   "source": [
    "# check attention mask\n",
    "index = (0, 0)\n",
    "cdd_token_id = x['cdd_token_id'][index]\n",
    "cdd_attn_mask = x[\"cdd_attn_mask\"][index]\n",
    "his_token_id = x[\"his_token_id\"][index]\n",
    "his_attn_mask = x[\"his_attn_mask\"][index]\n",
    "\n",
    "cdd_token = t.convert_ids_to_tokens(cdd_token_id)\n",
    "his_token = t.convert_ids_to_tokens(his_token_id)\n",
    "\n",
    "line = \"{:20} a \".format(\" \"*20)\n",
    "print(line)\n",
    "for i in range(manager.sequence_length):\n",
    "    line = \"{:20} {}\".format(cdd_token[i], cdd_attn_mask[i])\n",
    "    print(line)\n",
    "    if cdd_token[i] == \"[PAD]\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train loader result\n",
    "nid2index = load_pickle(\"/data/v-pezhang/Code/GateFormer/src/data/cache/MIND/MINDdemo_train/news/nid2index.pkl\")\n",
    "uid2index = load_pickle(\"/data/v-pezhang/Code/GateFormer/src/data/cache/MIND/uid2index.pkl\")\n",
    "nindex2id = {v:k for k,v in nid2index.items()}\n",
    "uindex2id = {v:k for k,v in uid2index.items()}\n",
    "\n",
    "# check behaviors.tsv\n",
    "print([uindex2id[i] for i in x[\"user_index\"].tolist()], (x[\"impr_index\"] + 1).tolist())\n",
    "# check news.tsv\n",
    "print([nindex2id[i] for i in x[\"cdd_idx\"][0][:5].tolist()])\n",
    "print(t.batch_decode(x[\"cdd_token_id\"][0][:5], skip_special_tokens=True))\n",
    "\n",
    "print([nindex2id[i] for i in x[\"his_idx\"][0][:5].tolist()])\n",
    "print(t.batch_decode(x[\"his_token_id\"][0][:5], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dev loader result\n",
    "nid2index = load_pickle(\"/data/v-pezhang/Code/GateFormer/src/data/cache/MIND/MINDdemo_dev/news/nid2index.pkl\")\n",
    "uid2index = load_pickle(\"/data/v-pezhang/Code/GateFormer/src/data/cache/MIND/uid2index.pkl\")\n",
    "nindex2id = {v:k for k,v in nid2index.items()}\n",
    "uindex2id = {v:k for k,v in uid2index.items()}\n",
    "\n",
    "# check behaviors.tsv\n",
    "print([uindex2id[i] for i in x2[\"user_index\"].tolist()], (x2[\"impr_index\"] + 1).tolist())\n",
    "# check news.tsv\n",
    "print([nindex2id[i] for i in x2[\"cdd_idx\"][0][:5].tolist()])\n",
    "print(t.batch_decode(x2[\"cdd_token_id\"][0][:5], skip_special_tokens=True))\n",
    "\n",
    "print([nindex2id[i] for i in x2[\"his_idx\"][0][:5].tolist()])\n",
    "print(t.batch_decode(x2[\"his_token_id\"][0][:5], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a256a4def3bbb1bd6a1d46703c4995443a919758d62b261face579c969ba8076"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
