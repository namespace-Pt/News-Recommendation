{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".ipynb",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnncondad67fb259925d4833a703b0467175fd55",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3eb98a31bb4fe483f921d6d3a56a708e0ea8295072fddff1b0a8d949ab7fd102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from utils.utils import train,prepare,evaluate,tune\n",
    "from models.Interactors import FIM_Interactor, KNRM_Interactor\n",
    "from models.Encoders.FIM import FIM_Encoder\n",
    "from models.SFI import SFI_gating, SFI_gating_MultiView\n",
    "from configs.ManualConfig import hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='sfi'\n",
    "hparams['k'] = 30\n",
    "hparams['his_size'] = 50\n",
    "hparams['select'] = 'gating'\n",
    "hparams['onehot'] = True\n",
    "hparams['device'] = 'cuda:0'\n",
    "# hparams['threshold'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hparams['validate'] = True\n",
    "vocab, loaders = prepare(hparams, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = next(iter(loaders[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math,random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.Interactors import FIM_Interactor\n",
    "\n",
    "class SFI_gating(nn.Module):\n",
    "    def __init__(self, hparams, encoder, interactor=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cdd_size = (hparams['npratio'] +\n",
    "                         1) if hparams['npratio'] > 0 else 1\n",
    "        self.batch_size = hparams['batch_size']\n",
    "        self.his_size = hparams['his_size']\n",
    "        self.signal_length = hparams['title_size']\n",
    "\n",
    "        self.k = hparams['k']\n",
    "\n",
    "        # contrasive learning deprecated\n",
    "        self.contra_num = 0\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.level = encoder.level\n",
    "        self.hidden_dim = encoder.hidden_dim\n",
    "\n",
    "        # concatenate category embedding and subcategory embedding\n",
    "\n",
    "        self.device = hparams['device']\n",
    "        # elements in the slice along dim will sum up to 1\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        if not interactor:\n",
    "            self.interactor = FIM_Interactor(self.level)\n",
    "        else:\n",
    "            self.interactor = interactor\n",
    "\n",
    "        final_dim = int(int(self.k / 3) /3) * int(int(self.signal_length / 3) / 3)**2 * 16\n",
    "        self.learningToRank = nn.Linear(final_dim, 1)\n",
    "\n",
    "        self.name = '-'.join(['sfi-gating', self.encoder.name, self.interactor.name])\n",
    "\n",
    "        self.selectionProject = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, self.hidden_dim//2, batch_first=True, bidirectional=True)\n",
    "\n",
    "        if hasattr(self,'selectionProject'):\n",
    "            if isinstance(self.selectionProject, nn.Linear):\n",
    "                    nn.init.xavier_normal_(self.selectionProject.weight)\n",
    "            else:\n",
    "                for param in self.selectionProject:\n",
    "                    if isinstance(param, nn.Linear):\n",
    "                        nn.init.xavier_normal_(param.weight)\n",
    "\n",
    "        nn.init.xavier_normal_(self.learningToRank.weight)\n",
    "\n",
    "        if 'threshold' in hparams and hparams['threshold']:\n",
    "            threshold = torch.tensor([hparams['threshold']])\n",
    "            self.register_buffer('threshold', threshold)\n",
    "            if self.k != self.his_size:\n",
    "                raise ValueError(\"K value not matched!\")\n",
    "\n",
    "    def _news_attention(self, cdd_repr, his_repr, his_embedding, his_mask):\n",
    "        \"\"\" apply news-level attention\n",
    "\n",
    "        Args:\n",
    "            cdd_repr: tensor of [batch_size, cdd_size, hidden_dim]\n",
    "            his_repr: tensor of [batch_size, his_size, hidden_dim]\n",
    "            his_embedding: tensor of [batch_size, his_size, signal_length, level, *]\n",
    "            his_mask: tensor of [batch_size, his_size, 1]\n",
    "\n",
    "        Returns:\n",
    "            his_activated: tensor of [batch_size, cdd_size, k, signal_length, *]\n",
    "            his_focus: tensor of [batch_size, cdd_size, k, his_size]\n",
    "            pos_repr: tensor of [batch_size, cdd_size, contra_num, hidden_dim]\n",
    "            neg_repr: tensor of [batch_size, cdd_size, contra_num, hidden_dim]\n",
    "        \"\"\"\n",
    "        # [bs, cs, hs]\n",
    "        if hasattr(self, 'threshold'):\n",
    "            attn_weights = F.normalize(self.selectionProject(cdd_repr), dim=-1).matmul(F.normalize(self.selectionProject(his_repr),dim=-1).transpose(-2,-1))\n",
    "            # attn_weights = F.normalize(cdd_repr, dim=-1).matmul(F.normalize(his_repr, dim=-1).transpose(-1, -2))\n",
    "            print(attn_weights[0][1])\n",
    "\n",
    "            his_activated = his_embedding.unsqueeze(dim=1) * (attn_weights.masked_fill(attn_weights<self.threshold, 0).view(self.batch_size, self.cdd_size, self.k, 1, 1, 1))\n",
    "\n",
    "            output = (his_activated, None)\n",
    "\n",
    "        else:\n",
    "            cdd_repr = self.selectionProject(cdd_repr)\n",
    "            his_repr = self.selectionProject(his_repr)\n",
    "\n",
    "            attn_weights = cdd_repr.matmul(his_repr.transpose(-1, -2))\n",
    "\n",
    "            # Masking off these 0s will force the gumbel_softmax to attend to only non-zero histories.\n",
    "            # Masking in candidate also cause such a problem, however we donot need to fix it\n",
    "            \n",
    "            attn_weights = self.softmax(attn_weights.masked_fill(his_mask.transpose(-1, -2), -float(\"inf\")))\n",
    "            # attn_weights = self.softmax(attn_weights)\n",
    "\n",
    "            _, attn_weights_sorted = attn_weights.detach().sort(dim=-1, descending=True)\n",
    "\n",
    "            # use scatter to map the index tensor to one-hot encoding, this is faster than F.one_hot\n",
    "            attn_focus = torch.zeros(self.batch_size, self.cdd_size, self.k, self.his_size,device=self.device)\n",
    "            src = torch.ones(self.batch_size, self.cdd_size, self.k, self.his_size,device=self.device)\n",
    "            his_focus = attn_focus.scatter(-1, attn_weights_sorted[:, :, :self.k].unsqueeze(dim=-1), src)\n",
    "\n",
    "            # [bs, cs, k, sl, level, fn]\n",
    "            his_activated = torch.matmul(his_focus, his_embedding.reshape(\n",
    "                self.batch_size, 1, self.his_size, -1)).view(self.batch_size, self.cdd_size, self.k, -1, self.level, self.hidden_dim)\n",
    "\n",
    "            output = (his_activated, his_focus)\n",
    "        return output\n",
    "\n",
    "    def _click_predictor(self, fusion_tensors):\n",
    "        \"\"\" calculate batch of click probabolity\n",
    "\n",
    "        Args:\n",
    "            fusion_tensors: tensor of [batch_size, cdd_size, *]\n",
    "\n",
    "        Returns:\n",
    "            score: tensor of [batch_size, cdd_size], which is normalized click probabilty\n",
    "        \"\"\"\n",
    "        score = self.learningToRank(fusion_tensors).squeeze(dim=-1)\n",
    "        return score\n",
    "\n",
    "    def forward_(self, x):\n",
    "        if x['candidate_title'].shape[0] != self.batch_size:\n",
    "            self.batch_size = x['candidate_title'].shape[0]\n",
    "\n",
    "        cdd_news = x['candidate_title'].long().to(self.device)\n",
    "        cdd_news_embedding, cdd_news_repr = self.encoder(\n",
    "            cdd_news,\n",
    "            user_index=x['user_index'].long().to(self.device),\n",
    "            news_id=x['cdd_id'].long().to(self.device),\n",
    "            attn_mask=x['candidate_title_pad'].to(self.device))\n",
    "\n",
    "        his_news = x['clicked_title'].long().to(self.device)\n",
    "        his_news_embedding, his_news_repr = self.encoder(\n",
    "            his_news,\n",
    "            user_index=x['user_index'].long().to(self.device),\n",
    "            news_id=x['his_id'].long().to(self.device),\n",
    "            attn_mask=x['clicked_title_pad'].to(self.device))\n",
    "\n",
    "        output = self._news_attention(\n",
    "            cdd_news_repr, his_news_repr, his_news_embedding, x['his_mask'].to(self.device))\n",
    "\n",
    "        if self.interactor.name == 'knrm':\n",
    "            cdd_pad = x['candidate_title_pad'].float().to(self.device).view(self.batch_size, self.cdd_size, 1, 1, -1, 1)\n",
    "            if output[1] is not None:\n",
    "                his_pad = torch.matmul(output[1], x['clicked_title_pad'].float().to(self.device).reshape(\n",
    "                    self.batch_size, 1, self.his_size, -1)).view(self.batch_size, self.cdd_size, self.k, 1, 1, -1, 1)\n",
    "            else:\n",
    "                his_pad = x['clicked_title_pad'].float().to(self.device).view(self.batch_size, 1, self.k, 1, 1, self.signal_length, 1).expand(self.batch_size, self.cdd_size, self.k, 1, 1, self.signal_length, 1)\n",
    "\n",
    "            fusion_tensors = self.interactor(cdd_news_embedding, output[0], cdd_pad=cdd_pad, his_pad=his_pad)\n",
    "\n",
    "        elif self.interactor.name == 'fim':\n",
    "            fusion_tensors = self.interactor(cdd_news_embedding, output[0])\n",
    "\n",
    "        return self._click_predictor(fusion_tensors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        score = self.forward_(x)\n",
    "        if self.cdd_size > 1:\n",
    "            score = nn.functional.log_softmax(score, dim=1)\n",
    "        else:\n",
    "            score = torch.sigmoid(score)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = FIM_Encoder(hparams, vocab)\n",
    "# interactor = KNRM_Interactor()\n",
    "hparams['name'] = '-'.join([name,encoder.name,hparams['select']])\n",
    "hparams['k'] = hparams['his_size']\n",
    "hparams['threshold'] = 0.3\n",
    "# sfi = SFI_gating_MultiView(hparams, encoder, interactor).to(hparams['device'])\n",
    "sfi = SFI_gating(hparams, encoder).to(hparams['device'])\n",
    "\n",
    "sfi.load_state_dict(torch.load('/home/peitian_zhang/Codes/News-Recommendation/data/model_params/sfi-fim-fim-gating/large_epoch5_step8458_[hs=50,topk=50,attrs=title].model', map_location=hparams['device'])['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfi(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sfi.selectionProject.weight.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams['epochs'] = 1\n",
    "train(sfi, hparams, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}