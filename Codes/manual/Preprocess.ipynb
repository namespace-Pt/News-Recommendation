{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from utils.utils import prepare,analyse,constructBasicDict,tailorData"
   ]
  },
  {
   "source": [
    "### Hyper parameters setting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'npratio':4,\n",
    "    'mode':'train',\n",
    "    'scale':'demo',\n",
    "    'batch_size':10,\n",
    "    'his_size':50,\n",
    "    'title_size':15,\n",
    "    'device':'cpu',\n",
    "    'attrs': ['title'],\n",
    "    'k': 0,\n",
    "    'validate':False\n",
    "}\n",
    "# torch.cuda.set_device(hparams['device'])"
   ]
  },
  {
   "source": [
    "### Construct necessary dictionaries\n",
    "- already done and the results are in `data/dictionaries`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructBasicDict(attrs=['title'],path='/home/peitian_zhang/Data/MIND')"
   ]
  },
  {
   "source": [
    "### View data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-03-21 09:27:33,701] INFO (root) Hyper Parameters are\n",
      "{'npratio': 4, 'mode': 'train', 'scale': 'demo', 'batch_size': 10, 'his_size': 50, 'title_size': 15, 'device': 'cpu', 'attrs': ['title'], 'k': 0, 'validate': False}\n",
      "[2021-03-21 09:27:33,702] INFO (root) preparing dataset...\n",
      "[2021-03-21 09:27:36,031] INFO (torchtext.vocab) Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n"
     ]
    }
   ],
   "source": [
    "vocab, loaders = prepare(hparams, pin_memory=False)\n",
    "\n",
    "# for encoding news only\n",
    "# vocab, loaders = prepare(hparams, news=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader_train\n",
    "a = next(iter(loaders[0]))\n",
    "# loader_dev\n",
    "b = next(iter(loaders[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 8.6673e-01, -2.3187e+00,  4.8320e-01,  ...,  1.0779e+00,\n",
       "           7.0819e-01,  5.2822e-01],\n",
       "         [ 5.1428e-02, -2.5159e-04, -1.0456e+00,  ..., -5.9466e-01,\n",
       "           2.5224e-01, -1.3118e+00],\n",
       "         [ 1.1149e+00, -8.8765e-01, -1.4817e-01,  ...,  2.2986e-01,\n",
       "          -2.6257e-01,  3.2976e-01],\n",
       "         ...,\n",
       "         [-1.3801e-01,  1.5101e+00,  6.2164e-01,  ...,  1.3304e+00,\n",
       "           5.8683e-01,  5.8839e-01],\n",
       "         [ 7.5770e-01,  2.8950e-01, -2.6903e-01,  ...,  5.4247e-01,\n",
       "          -4.6608e-01,  2.8433e-01],\n",
       "         [ 2.8993e-01,  1.8119e+00, -1.8658e-01,  ...,  3.1166e-01,\n",
       "          -2.9683e+00, -6.0720e-01]], requires_grad=True),\n",
       " tensor([[[ 5.1428e-02, -2.5159e-04, -1.0456e+00,  9.7266e-01,  9.2905e-01,\n",
       "            6.8950e-01, -1.3658e+00, -5.9466e-01,  2.5224e-01, -1.3118e+00]],\n",
       " \n",
       "         [[ 1.1149e+00, -8.8765e-01, -1.4817e-01, -2.8997e-01, -9.8578e-01,\n",
       "           -4.0253e-01,  1.2189e+00,  2.2986e-01, -2.6257e-01,  3.2976e-01]],\n",
       " \n",
       "         [[-8.5825e-01,  5.7503e-01, -1.9676e+00,  5.0369e-01, -9.8121e-01,\n",
       "            7.7653e-01,  2.3889e-01, -1.9848e+00, -1.6858e-01, -4.1367e-01]]],\n",
       "        grad_fn=<EmbeddingBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "embedding = torch.nn.Embedding(20000,10)\n",
    "embedding(a['user_index']).shape\n",
    "a['user_index'] = torch.tensor([[1],[2],[3]])\n",
    "embedding.weight, embedding(a['user_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tailor Data to demo size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tailor 2000 impressions from MINDsmall_train to form MINDdemo_train\n",
    "tailorData('/home/peitian_zhang/Data/MIND/MINDsmall_train/behaviors.tsv',2000)\n",
    "\n",
    "tailorData('/home/peitian_zhang/Data/MIND/MINDsmall_dev/behaviors.tsv',500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze MIND Datasets\n",
    "- average title length\n",
    "- average abstract length\n",
    "- average history length\n",
    "- average impression capacity\n",
    "- count of history exceeding 50\n",
    "- count of empty history\n",
    "- count of multi-clicked impressions "
   ]
  },
  {
   "source": [
    "analyse(hparams)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## The rest is developing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from utils.utils import prepare,analyse,constructBasicDict,tailorData\n",
    "from utils.MIND import MIND\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "from utils.utils import newsample, getId2idx, word_tokenize_vocab, getVocab, my_collate, worker_init_fn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'npratio':4,\n",
    "    'mode':'train',\n",
    "    'scale':'demo',\n",
    "    'batch_size':10,\n",
    "    'his_size':50,\n",
    "    'title_size':15,\n",
    "    'device':'cuda:1',\n",
    "    'attrs': ['title'],\n",
    "    'news_id':True,\n",
    "    'k': 0,\n",
    "    'validate':False,\n",
    "    'bert':'bert-base-uncased'\n",
    "}\n",
    "# torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mind = MIND(hparams, '/home/peitian_zhang/Data/MIND/MINDdemo_dev/news.tsv', '/home/peitian_zhang/Data/MIND/MINDdemo_dev/behaviors.tsv')\n",
    "\n",
    "loader_train = DataLoader(mind, batch_size=hparams['batch_size'], pin_memory=True,\n",
    "                                  num_workers=0, drop_last=False, collate_fn=my_collate, worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = next(mind.__iter__())\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record['candidate_title'].shape, record['candidate_title_pad'].shape, record['clicked_title'].shape, record['clicked_title_pad'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}