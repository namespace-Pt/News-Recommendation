{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnncondad67fb259925d4833a703b0467175fd55",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "3eb98a31bb4fe483f921d6d3a56a708e0ea8295072fddff1b0a8d949ab7fd102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from utils.utils import prepare,analyse,constructBasicDict,tailorData"
   ]
  },
  {
   "source": [
    "### Hyper parameters setting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'npratio':4,\n",
    "    'mode':'train',\n",
    "    'scale':'demo',\n",
    "    'batch_size':10,\n",
    "    'his_size':50,\n",
    "    'title_size':15,\n",
    "    'abs_size':20,\n",
    "    'device':'cpu',\n",
    "    'attrs': ['title'],\n",
    "    'k': 0,\n",
    "    'validate':False,\n",
    "    'onehot':True\n",
    "}\n",
    "# torch.cuda.set_device(hparams['device'])"
   ]
  },
  {
   "source": [
    "### Construct necessary dictionaries\n",
    "- already done and the results are in `data/dictionaries`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructBasicDict(attrs=['title'],path='/home/peitian_zhang/Data/MIND')"
   ]
  },
  {
   "source": [
    "### View data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'loaders' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-16bf4a35e34e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loaders' is not defined"
     ]
    }
   ],
   "source": [
    "list(loaders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-04-17 17:25:39,776] INFO (root) Hyper Parameters are\n",
      "{'npratio': 4, 'mode': 'train', 'scale': 'demo', 'batch_size': 10, 'his_size': 50, 'title_size': 15, 'abs_size': 20, 'device': 'cpu', 'attrs': ['title'], 'k': 0, 'validate': False, 'onehot': True}\n",
      "[2021-04-17 17:25:39,778] INFO (root) preparing dataset...\n",
      "[2021-04-17 17:25:43,480] INFO (torchtext.vocab) Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n"
     ]
    }
   ],
   "source": [
    "vocab, loaders = prepare(hparams, pin_memory=False)\n",
    "\n",
    "# for encoding news only\n",
    "# vocab, loaders = prepare(hparams, news=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader_train\n",
    "a = next(iter(loaders[0]))\n",
    "# loader_dev\n",
    "b = next(iter(loaders[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['candidate_vert_onehot'].shape, b['clicked_ver']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tailor Data to demo size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tailor 2000 impressions from MINDsmall_train to form MINDdemo_train\n",
    "tailorData('/home/peitian_zhang/Data/MIND/MINDsmall_train/behaviors.tsv',2000)\n",
    "\n",
    "tailorData('/home/peitian_zhang/Data/MIND/MINDsmall_dev/behaviors.tsv',500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze MIND Datasets\n",
    "- average title length\n",
    "- average abstract length\n",
    "- average history length\n",
    "- average impression capacity\n",
    "- count of history exceeding 50\n",
    "- count of empty history\n",
    "- count of multi-clicked impressions "
   ]
  },
  {
   "source": [
    "analyse(hparams)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## The rest is for developing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "\n",
    "hparams = {\n",
    "    'npratio':4,\n",
    "    'mode':'train',\n",
    "    'scale':'demo',\n",
    "    'batch_size':2,\n",
    "    'his_size':50,\n",
    "    'title_size':15,\n",
    "    'abs_size':20,\n",
    "    'device':'cpu',\n",
    "    'attrs': ['title'],\n",
    "    'k': 20,\n",
    "    'validate':False,\n",
    "    'onehot':False\n",
    "}\n",
    "# torch.cuda.set_device(hparams['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from torch.utils.data import Dataset\n",
    "from utils.utils import newsample, getId2idx, tokenize, getVocab\n",
    "\n",
    "class MIND(Dataset):\n",
    "    \"\"\" Map Style Dataset for MIND, return positive samples with negative sampling when training, or return each sample when developing.\n",
    "\n",
    "    Args:\n",
    "        hparams(dict): pre-defined dictionary of hyper parameters\n",
    "        news_file(str): path of news_file\n",
    "        behaviors_file(str): path of behaviors_file\n",
    "        shuffle(bool): whether to shuffle the order of impressions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hparams, news_file, behaviors_file, shuffle_pos=False, validate=False):\n",
    "        # initiate the whole iterator\n",
    "        self.npratio = hparams['npratio']\n",
    "        self.shuffle_pos = shuffle_pos\n",
    "\n",
    "        self.news_file = news_file\n",
    "        self.behaviors_file = behaviors_file\n",
    "        self.col_spliter = '\\t'\n",
    "        self.batch_size = hparams['batch_size']\n",
    "        self.title_size = hparams['title_size']\n",
    "        self.abs_size = hparams['abs_size']\n",
    "        self.his_size = hparams['his_size']\n",
    "\n",
    "        self.onehot = hparams['onehot']\n",
    "\n",
    "        if 'k' in hparams:\n",
    "            self.k = hparams['k']\n",
    "\n",
    "        self.mode = re.search(\n",
    "            '{}_(.*)/'.format(hparams['scale']), news_file).group(1)\n",
    "\n",
    "        # there are only two types of vocabulary\n",
    "        self.vocab = getVocab('data/dictionaries/vocab_whole.pkl')\n",
    "\n",
    "        self.nid2index = getId2idx(\n",
    "            'data/dictionaries/nid2idx_{}_{}.json'.format(hparams['scale'], self.mode))\n",
    "        self.uid2index = getId2idx(\n",
    "            'data/dictionaries/uid2idx_{}.json'.format(hparams['scale']))\n",
    "        self.vert2onehot = getId2idx(\n",
    "            'data/dictionaries/vert2onehot.json'\n",
    "        )\n",
    "        self.subvert2onehot = getId2idx(\n",
    "            'data/dictionaries/subvert2onehot.json'\n",
    "        )\n",
    "\n",
    "        if validate:\n",
    "            self.mode = 'dev'\n",
    "\n",
    "        self.init_news()\n",
    "        self.init_behaviors()\n",
    "\n",
    "    def init_news(self):\n",
    "        \"\"\"\n",
    "            init news information given news file, such as news_title_array.\n",
    "        \"\"\"\n",
    "\n",
    "        # VERY IMPORTANT!!! FIXME\n",
    "        # The nid2idx dictionary must follow the original order of news in news.tsv\n",
    "\n",
    "        titles = [[1]*self.title_size]\n",
    "        title_pad = [[self.title_size]]\n",
    "        abstracts = [[1]*self.abs_size]\n",
    "        abs_pad = [[self.abs_size]]\n",
    "\n",
    "        # pure text of the title\n",
    "        # titles = [['hello MIND']]\n",
    "        categories = [[1]]\n",
    "        subcategories = [[1]]\n",
    "\n",
    "        with open(self.news_file, \"r\", encoding='utf-8') as rd:\n",
    "            for idx in rd:\n",
    "                nid, vert, subvert, title, ab, url, _, _ = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "\n",
    "                title_token = tokenize(title, self.vocab)\n",
    "                titles.append(title_token[:self.title_size] + [1] * (self.title_size - len(title_token)))\n",
    "                title_pad.append([max(self.title_size - len(title_token), 0)])\n",
    "\n",
    "                abs_token = tokenize(ab, self.vocab)\n",
    "                abstracts.append(abs_token[:self.abs_size] + [1] * (self.abs_size - len(abs_token)))\n",
    "                abs_pad.append([max(self.abs_size - len(abs_token), 0)])\n",
    "\n",
    "                categories.append(tokenize(vert, self.vocab))\n",
    "                subcategories.append(tokenize(subvert, self.vocab))\n",
    "\n",
    "        # self.titles = titles\n",
    "        self.news_title_array = np.asarray(titles)\n",
    "        self.title_pad = np.asarray(title_pad)\n",
    "        self.abs_array = np.asarray(abstracts)\n",
    "        self.abs_pad = np.asarray(abs_pad)\n",
    "        self.vert_array = np.asarray(categories)\n",
    "        self.subvert_array = np.asarray(subcategories)\n",
    "\n",
    "    def init_behaviors(self):\n",
    "        \"\"\"\n",
    "            init behavior logs given behaviors file.\n",
    "        \"\"\"\n",
    "        # list of list of history news index\n",
    "        self.histories = []\n",
    "        # list of user index\n",
    "        self.uindexes = []\n",
    "        # list of list of history padding length\n",
    "        self.his_pad = []\n",
    "        # list of impression indexes\n",
    "        # self.impr_indexes = []\n",
    "\n",
    "        # only store positive behavior\n",
    "        if self.mode == 'train':\n",
    "            # list of list of clicked candidate news index along with its impression index\n",
    "            self.imprs = []\n",
    "            # dictionary of list of unclicked candidate news index\n",
    "            self.negtives = {}\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    impr_index, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "                    # important to subtract 1 because all list related to behaviors start from 0\n",
    "                    impr_index = int(impr_index) - 1\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    if self.k:\n",
    "                        # guarantee there are at least k history not masked\n",
    "                        self.his_pad.append(\n",
    "                            min(max(self.his_size - len(history), 0), self.his_size - self.k))\n",
    "                    else:\n",
    "                        self.his_pad.append(max(self.his_size - len(history), 0))\n",
    "\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.his_size] + [0] * (self.his_size - len(history))\n",
    "                    impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
    "                    labels = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store negative samples of each impression\n",
    "                    negatives = []\n",
    "\n",
    "                    for news, label in zip(impr_news, labels):\n",
    "                        if label == 1:\n",
    "                            self.imprs.append((impr_index, news))\n",
    "                        else:\n",
    "                            negatives.append(news)\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    self.histories.append(history)\n",
    "                    self.negtives[impr_index] = negatives\n",
    "                    self.uindexes.append(uindex)\n",
    "\n",
    "        # store every behaviors\n",
    "        elif self.mode == 'dev':\n",
    "            # list of every candidate news index along with its impression index and label\n",
    "            self.imprs = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    impr_index, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "                    impr_index = int(impr_index) - 1\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    if self.k:\n",
    "                        # guarantee there are at least k history not masked\n",
    "                        self.his_pad.append(\n",
    "                            min(max(self.his_size - len(history), 0), self.his_size - self.k))\n",
    "                    else:\n",
    "                        self.his_pad.append(max(self.his_size - len(history), 0))\n",
    "\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.his_size] + [0] * (self.his_size - len(history))\n",
    "                    impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
    "                    labels = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store every impression\n",
    "                    for news, label in zip(impr_news, labels):\n",
    "                        self.imprs.append((impr_index, news, label))\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    self.histories.append(history)\n",
    "                    self.uindexes.append(uindex)\n",
    "\n",
    "        # store every behaviors\n",
    "        elif self.mode == 'test':\n",
    "            # list of every candidate news index along with its impression index and label\n",
    "            self.imprs = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    impr_index, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "                    impr_index = int(impr_index) - 1\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    if self.k:\n",
    "                        # guarantee there are at least k history not masked\n",
    "                        self.his_pad.append(\n",
    "                            min(max(self.his_size - len(history), 0), self.his_size - self.k))\n",
    "                    else:\n",
    "                        self.his_pad.append(max(self.his_size - len(history), 0))\n",
    "\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.his_size] + [0] * (self.his_size - len(history))\n",
    "                    impr_news = [self.nid2index[i] for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store every impression\n",
    "                    for news in impr_news:\n",
    "                        self.imprs.append((impr_index, news))\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    self.histories.append(history)\n",
    "                    self.uindexes.append(uindex)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "            return length of the whole dataset\n",
    "        \"\"\"\n",
    "        return len(self.imprs)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \"\"\" return data\n",
    "        Args:\n",
    "            index: the index for stored impression\n",
    "\n",
    "        Returns:\n",
    "            back_dic: dictionary of data slice\n",
    "        \"\"\"\n",
    "\n",
    "        impr = self.imprs[index] # (impression_index, news_index)\n",
    "        impr_index = impr[0]\n",
    "        impr_news = impr[1]\n",
    "\n",
    "        user_index = [self.uindexes[impr_index]]\n",
    "\n",
    "        # each time called to return positive one sample and its negative samples\n",
    "        if self.mode == 'train':\n",
    "            # user's unclicked news in the same impression\n",
    "            negs = self.negtives[impr_index]\n",
    "            neg_list, neg_pad = newsample(negs, self.npratio)\n",
    "\n",
    "            cdd_ids = np.asarray([impr_news] + neg_list)\n",
    "            label = np.asarray([1] + [0] * self.npratio)\n",
    "\n",
    "            if self.shuffle_pos:\n",
    "                s = np.arange(0, len(label), 1)\n",
    "                np.random.shuffle(s)\n",
    "                cdd_ids = np.asarray(cdd_ids)[s]\n",
    "                label = np.asarray(label)[s]\n",
    "\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size, 1), dtype=bool)\n",
    "            his_ids = self.histories[impr_index]\n",
    "\n",
    "            # in case the user has no history records, do not mask\n",
    "            if self.his_pad[impr_index] == self.his_size or self.his_pad[impr_index] == 0:\n",
    "                his_mask = his_mask\n",
    "            else:\n",
    "                his_mask[-self.his_pad[impr_index]:] = [True]\n",
    "\n",
    "            # pad in candidate\n",
    "            # candidate_mask = [1] * neg_pad + [0] * (self.npratio + 1 - neg_pad)\n",
    "\n",
    "            # pad in title\n",
    "            candidate_title_pad = [(self.title_size - i[0])*[1] + i[0]*[0] for i in self.title_pad[cdd_ids]]\n",
    "            clicked_title_pad = [(self.title_size - i[0])*[1] + i[0]*[0] for i in self.title_pad[his_ids]]\n",
    "            candidate_abs_pad = [(self.abs_size - i[0])*[1] + i[0]*[0] for i in self.abs_pad[cdd_ids]]\n",
    "            clicked_abs_pad = [(self.abs_size - i[0])*[1] + i[0]*[0] for i in self.abs_pad[his_ids]]\n",
    "\n",
    "            candidate_title_index = self.news_title_array[cdd_ids]\n",
    "            clicked_title_index = self.news_title_array[his_ids]\n",
    "            candidate_abs_index = self.abs_array[cdd_ids]\n",
    "            clicked_abs_index = self.abs_array[his_ids]\n",
    "            candidate_vert_index = self.vert_array[cdd_ids]\n",
    "            clicked_vert_index = self.vert_array[his_ids]\n",
    "            candidate_subvert_index = self.subvert_array[cdd_ids]\n",
    "            clicked_subvert_index = self.subvert_array[his_ids]\n",
    "\n",
    "            back_dic = {\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                # \"cdd_mask\": np.asarray(neg_pad),\n",
    "                'cdd_id': cdd_ids,\n",
    "                \"candidate_title\": candidate_title_index,\n",
    "                \"candidate_title_pad\": np.asarray(candidate_title_pad),\n",
    "                \"candidate_abs\": candidate_abs_index,\n",
    "                \"candidate_abs_pad\": np.asarray(candidate_abs_pad),\n",
    "                \"candidate_vert\": candidate_vert_index,\n",
    "                \"candidate_subvert\": candidate_subvert_index,\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"clicked_title\": clicked_title_index,\n",
    "                \"clicked_title_pad\": np.asarray(clicked_title_pad),\n",
    "                \"clicked_abs\": clicked_abs_index,\n",
    "                \"clicked_abs_pad\": np.asarray(clicked_abs_pad),\n",
    "                \"clicked_vert\": clicked_vert_index,\n",
    "                \"clicked_subvert\": clicked_subvert_index,\n",
    "                \"his_mask\": his_mask,\n",
    "                \"labels\": label\n",
    "            }\n",
    "\n",
    "            if self.onehot:\n",
    "                candidate_vert_onehot = [self.vert2onehot[str(i[0])] for i in candidate_vert_index]\n",
    "                clicked_vert_onehot = [self.vert2onehot[str(i[0])] for i in clicked_vert_index]\n",
    "\n",
    "                candidate_subvert_onehot = [self.subvert2onehot[str(i[0])] for i in candidate_subvert_index]\n",
    "                clicked_subvert_onehot = [self.subvert2onehot[str(i[0])] for i in clicked_subvert_index]\n",
    "\n",
    "                back_dic['candidate_vert_onehot'] = np.asarray(candidate_vert_onehot)\n",
    "                back_dic['clicked_vert_onehot'] = np.asarray(clicked_vert_onehot)\n",
    "                back_dic['candidate_subvert_onehot'] = np.asarray(candidate_subvert_onehot)\n",
    "                back_dic['clicked_subvert_onehot'] = np.asarray(clicked_subvert_onehot)\n",
    "\n",
    "            return back_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hparams['mode'] = 'dev'\n",
    "hparams['onehot'] = True\n",
    "path='/home/peitian_zhang/Data/MIND'\n",
    "news_file = path+'/MIND'+hparams['scale']+'_{}/news.tsv'.format(hparams['mode'])\n",
    "behavior_file = path+'/MIND' + hparams['scale']+'_{}/behaviors.tsv'.format(hparams['mode'])\n",
    "dataset = MIND(hparams=hparams, news_file=news_file,behaviors_file=behavior_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'user_index': array([14]),\n",
       " 'cdd_id': array([42167, 32185, 50603, 32961, 34596]),\n",
       " 'candidate_title': array([[32021, 15420,     9,   951,     6,  1626,     6,   903,    29,\n",
       "           732,   199,   151,   289,    20,   217],\n",
       "        [  699, 16805,    55,  1984,    11,   954,  6895,   468,  5295,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [ 1208, 11545,    23,  5080,     5,  2449, 15821, 15666,  1134,\n",
       "           268,   133,  2327,  1828,   158,     1],\n",
       "        [ 1235,  1327,   264,   229,  1501,    19, 16187,   544,   114,\n",
       "             6,    88,   561,     6, 12031, 21875],\n",
       "        [   84,  4063,  2517,   694,    51, 45399, 20987,  2416,     1,\n",
       "             1,     1,     1,     1,     1,     1]]),\n",
       " 'candidate_title_pad': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'candidate_abs': array([[32021, 15420,     9,   951,   903,    29,   732,   199,   151,\n",
       "           289,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [  699, 16805,    55,  1984,    11,   954,  6895,   468,  5295,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [    8,   134,   222,   336,  2044,     8,     3,    16,  1279,\n",
       "            12,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [ 1235,     9,   264,   229,    73,  1501,  2800,    15, 33476,\n",
       "            88,    10,  6682,     6,   544,  3494,    10, 25018,     6,\n",
       "          3307,   112],\n",
       "        [  123,  1280,   445,    99,     8,  7779, 21884,    11, 19499,\n",
       "          1669,   962, 45399,    16,   431,   903,    15,   218,    11,\n",
       "          1201, 19288]]),\n",
       " 'candidate_abs_pad': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'candidate_vert': array([[100],\n",
       "        [  3],\n",
       "        [ 88],\n",
       "        [ 21],\n",
       "        [  3]]),\n",
       " 'candidate_subvert': array([[ 910],\n",
       "        [  34],\n",
       "        [3869],\n",
       "        [ 216],\n",
       "        [  63]]),\n",
       " 'his_id': array([ 2382, 15533, 24759,  7248,  4886, 15003,  8705, 17428, 11654,\n",
       "        11654, 19090,  8595, 24358, 12932, 21926, 24360,  6735, 11466,\n",
       "        10528,  4233, 16511, 30035, 22934, 17460, 14534,   976, 13998,\n",
       "        23914, 24068, 24068, 24502, 29969, 31685,   766, 21077,  7615,\n",
       "        15882,  3460,  8699, 31726, 18328, 21424, 17161, 31755, 22674,\n",
       "        31181, 19731, 14994, 26361, 33773]),\n",
       " 'clicked_title': array([[26908,  1599,   111,     5,  4739,     6,  3481,  5422,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [ 1964, 18982,  1726,     7,    66, 10440,   314,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [   42,  2243,   411, 15809,    22,   197,  2849,     8,    78,\n",
       "            29,     8,  8074,     5,  1530,   138],\n",
       "        [  392,     9,    15,  6987,  3284,   393,  8587,     7,    42,\n",
       "           462, 12706,    12,    86,    36,   790],\n",
       "        [   94,     8,   306, 23759,  1613,     7,     8,  3510,   812,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [ 5674,  9252,   667,    12,  1355,    85,   783,     5,   991,\n",
       "          3382,   716,     1,     1,     1,     1],\n",
       "        [ 1044, 12817, 15566,   446,  1652,  9921,  5063,    10,   217,\n",
       "          1499,   154,  4804,  4162,     1,     1],\n",
       "        [39903,  3120,  3644,  2089,     9,  1956,    11,  5235,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [  619,  2901,   273,    94, 12926,   143, 37195,   658,    95,\n",
       "          5980,   154,    65,   122,    11,   124],\n",
       "        [  619,  2901,   273,    94, 12926,   143, 37195,   658,    95,\n",
       "          5980,   154,    65,   122,    11,   124],\n",
       "        [   46,    43,     9,   224,     5,  1405,    10,  1838,  2698,\n",
       "            17,  1058,  2152,     6,  1037,     5],\n",
       "        [   97, 14803,   943,    16,  7564,    11,   449,   201,   337,\n",
       "          1148,   349,   382,   894,     1,     1],\n",
       "        [ 4023,  1041,   185,    73,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [  114,  7670,  6409,  8222,    15,   723,   513,    16,  1483,\n",
       "            94,  2811,   133,   970,     1,     1],\n",
       "        [  185,   454,     5,  4252,   995,   326,    11,   101,     7,\n",
       "          1840,    11,  4343,     1,     1,     1],\n",
       "        [  739,   515,  1931,  4207, 12292,     7,   237,     5,   306,\n",
       "           118,   877,     1,     1,     1,     1],\n",
       "        [14672, 13998,  1185,  1479,  5006,     5,  4355,   133,  1656,\n",
       "         21544,   154,  4804,  2875,     1,     1],\n",
       "        [ 1477, 30945,   285,    61,    56,   244,     7,  1211,  1174,\n",
       "           325,    20,  6040,   208,     1,     1],\n",
       "        [   46,  2074,   351,  1251,   164,     5,  1105,    29,   124,\n",
       "           218,    65,   205,     1,     1,     1],\n",
       "        [  134,   849,  3701,    60,  2582,  5830,     9,  4525,   116,\n",
       "            56,   244,     7,   194,  1531,     1],\n",
       "        [10774,  6752,     9,  3902,  8201,    20, 45285, 10050,     6,\n",
       "          6198,  4943,     1,     1,     1,     1],\n",
       "        [   28,   481,   113,  1693, 10479,    10, 17728,  1431,    16,\n",
       "           133, 42159, 12119,     1,     1,     1],\n",
       "        [  176,   717,    49,  8298,     5,    56,  2069,    51,  7742,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [ 4810, 15098,  4931,  1471,   579,    19,   134,   688,  2068,\n",
       "          3884, 42147,    10,   241,  5085, 11698],\n",
       "        [ 1058,     9,     8,  2083,  4829,    23,    15, 10052,     6,\n",
       "         29480,  6944,   226,    18,     8,  4717],\n",
       "        [    8,    78,  1223,   946,  2176,   977,   102,  4021,    20,\n",
       "          2139,    58,   162,   436,  3189,     1],\n",
       "        [ 4115,   188,  1719,     7,   325,    11,   423,  3530,     9,\n",
       "           232,  8013,     1,     1,     1,     1],\n",
       "        [11840, 35402,   714,    11,   232, 25701,   152,     7,  1573,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [   97,  3472, 40924,    53,   484,     9,  2843,     7,  5583,\n",
       "         52292,  3131,   271,     1,     1,     1],\n",
       "        [   97,  3472, 40924,    53,   484,     9,  2843,     7,  5583,\n",
       "         52292,  3131,   271,     1,     1,     1],\n",
       "        [   22,  5798,    11,   877,   724,  5132,  2280,  1684,   220,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [  877,    59,  1809,    65,   466,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [ 5416,  3441,    19,   142,  1542, 12941,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [ 2223,  6371,  3339, 14917,   208,    18,  8378,    20,   405,\n",
       "           579,    19,  3714,     9,  1785,     1],\n",
       "        [    8,   449,  5360,  1005,     7,   432,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [13926, 28004,     9,   530,   318,   557,  1970,   687,     7,\n",
       "          1122,  3013,     1,     1,     1,     1],\n",
       "        [ 6103,   341,  8710,   667,   366,  4351,   349,   212,  5235,\n",
       "         19983,     1,     1,     1,     1,     1],\n",
       "        [13008, 22397,     9,   530,  1629, 24537,  1130,  6288,  4673,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [  113,   152,   225,     7,   290,    95,   103,   760,   129,\n",
       "            51,   133,   550, 16650,     6,    62],\n",
       "        [  819,   321,   998,    17,   120,   268,    54,   162,   834,\n",
       "          7387,     1,     1,     1,     1,     1],\n",
       "        [  653,   127,     9,    85,  1562,     8,  8784,    29,  1844,\n",
       "          3926,  8881,     5,    15,   124,  6253],\n",
       "        [ 1937,  1787,  1304,    20,   113,  7700,     7, 16568,    19,\n",
       "          4464,     1,     1,     1,     1,     1],\n",
       "        [   28,   814,  1057, 29276,  5941,   208,    18,  1100,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [  819, 14234,  1653,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [  268, 31761, 10660,     9,  5767,  1243,  1172,     5,   515,\n",
       "          1863,     9,   951, 19544,     1,     1],\n",
       "        [  106,  1613,     8, 20825, 31000,  1220,    17,    87,     9,\n",
       "            46,  1726,     1,     1,     1,     1],\n",
       "        [13059,  8977,  1366,  1957,    19, 11161,  1909,    33,     8,\n",
       "          1989, 51553,     6,  1374,    64,     3],\n",
       "        [  377,  2660,   496,  5533,  1080,     6,   877,  2980,   905,\n",
       "         24900,     1,     1,     1,     1,     1],\n",
       "        [    8,   545,   137,  1986,   792,   664,  1335,    18,  2115,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [ 7692, 10427,   847,   305,    11,  2442,  2955,   280,    10,\n",
       "           160,   151,     1,     1,     1,     1]]),\n",
       " 'clicked_title_pad': array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]),\n",
       " 'clicked_abs': array([[26908,    89,   405,  9019,    19,  6471,  1188,    12,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [  392,   103,    79,  3293,    97,     6,    79,    22,    29,\n",
       "          2335, 30372,    12,    17,   392,   760,    39,    56,    79,\n",
       "           247,  4767],\n",
       "        [ 2243,   411, 15809, 23740, 25897,    22,    10,  1803,   465,\n",
       "           883,  6416,    89,  1034,     8,    78,    22,    29,     8,\n",
       "          9984,     5],\n",
       "        [ 2490,     0,     0, 40042, 12131, 41903,  9791,     7,    71,\n",
       "         24467,     0,     6,  3623,   462,     0,    66, 20282,     8,\n",
       "          1989,    12],\n",
       "        [    0,    11,     8,  4223,   317,  2898,     5,     8,   306,\n",
       "         23759,   803,   259,     8,  7643,  3510,   812,    42,    44,\n",
       "           102,   400],\n",
       "        [   28,   276,  1128,  5674,  9252,   667,    12,    89, 14339,\n",
       "            85,   783,     5,   123,  7902,  7545,   160, 42993,    11,\n",
       "          1211,  3382],\n",
       "        [  198,   320,  1860,     7,   234,    12,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [ 1077,   273,   102,   775,  1049,     7,  2074,   753,    19,\n",
       "          1773,   118,    15,  2783,  1543,    66, 10414,   322,  2630,\n",
       "             1,     1],\n",
       "        [  619,    89,  5818,  3057,   160,   273,    94, 12926,   143,\n",
       "         37195,    16,  8026,   154,     8,  7990,  6958,    11,    65,\n",
       "           122,    11],\n",
       "        [  619,    89,  5818,  3057,   160,   273,    94, 12926,   143,\n",
       "         37195,    16,  8026,   154,     8,  7990,  6958,    11,    65,\n",
       "           122,    11],\n",
       "        [  112,    11,     8,  4921,  1673,     9,   706,   928,  1300,\n",
       "           103,     8,   105,   296, 10636,    10,     8,  2432,    17,\n",
       "          6544,    11],\n",
       "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [   87,     9,    54,     8,   758,  4111,    69,   350,  4100,\n",
       "           185,    42,   157,   158,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [    8,   513,     9,   648, 24232,  6409,    10, 19913,  2430,\n",
       "            16,   133,   951,     0,   154,     8,   246,    16,   492,\n",
       "           200,    12],\n",
       "        [   20,    15,  4967,  6888,    11,  4377,    26,  2668,   259,\n",
       "             8,   587,  8620,    17,  1771,   550,  4049,     5,   238,\n",
       "             8,    44],\n",
       "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [  106,   534,    85,   891,     5,   835,    36,   125,     6,\n",
       "           106,   534,   891,     5,    83,    36,  2531,    12,     1,\n",
       "             1,     1],\n",
       "        [    8,   761,   867,    72,   418,  1019,     9,   656,    89,\n",
       "          8189,  2772,    15,   325,   118,  3950,  1477, 30945,     6,\n",
       "            20,     8],\n",
       "        [   39,     8,   417,    17,   223,   670,   164,    15,  1096,\n",
       "           249,    15, 26389,    27,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [  116,  2582,  5830,     9,  4525,    56,   244,     7,  1531,\n",
       "            27,  1471,  1371,  3474,     7,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [10774,   103,  2032,     5,  3047,  5650,     6,   119,   362,\n",
       "            15,  3333,   399,     7, 10780,    12,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [    8,   113,    23,  2257,   594,     6,   186,    10,     8,\n",
       "             0,  2451, 12119,     6,   886,    89,   400, 15119,    12,\n",
       "             1,     1],\n",
       "        [   83,    99,     8,   185,  2845,    19,    15, 12383,    18,\n",
       "           112,    11,   176,  3506,   442,    12,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [ 4810, 15098,    89, 14467,    15,  1471,   579,    19,    71,\n",
       "           134,  2072,  3178,  3884,    11,  3884, 42147,    16,   559,\n",
       "             6,  1037],\n",
       "        [ 1058,     8,  2083,  4829,   915, 39809,   414,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [  826,     8,  2176,   215,    56,    15,  1238,   775,  2151,\n",
       "             6,   119,    46,    66,  1111,   645,   224,    23,  1581,\n",
       "            10,  1370],\n",
       "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [    8,   714,    11,    15,  7081,  2791, 25701,    94,  1149,\n",
       "           232,    20,    15,   248,   621,    16,    15, 21411,   725,\n",
       "            89,   400],\n",
       "        [    8,  3472,   590,   956,  1614,  2948, 15739,    12,   143,\n",
       "         19128,  5890,   787,    61,   332,   392,    12,     1,     1,\n",
       "             1,     1],\n",
       "        [    8,  3472,   590,   956,  1614,  2948, 15739,    12,   143,\n",
       "         19128,  5890,   787,    61,   332,   392,    12,     1,     1,\n",
       "             1,     1],\n",
       "        [   15,  8026,   804, 23221,    22,  2485,    15,   724,    18,\n",
       "          3601,   295,  5132,    28,   789,  2280,  1684,   220,   368,\n",
       "         26008,    12],\n",
       "        [    8,   306,   877,    39,   226,    10,   143,  1662,   922,\n",
       "            93,  1386,   118,     8,  1104,  1809,    12,     1,     1,\n",
       "             1,     1],\n",
       "        [ 1542,    23,   197,    15,  1635,    10,   252,   758,   158,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [ 2223,     9,  3339, 14917,   225,    18,  8378,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [    0, 37701,    15,   554,    11,     8,   449,  5360,   397,\n",
       "          1005,  1173,    73,  1221,    29,  8846,    12,    29, 53799,\n",
       "             5,  1051],\n",
       "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [ 7763,     6,  5177,    12,  1128,   134,   128,   341, 10819,\n",
       "          8710,   667,    12, 14339,   783,   346,     5, 11614,   123,\n",
       "         10459,   391],\n",
       "        [ 1629, 22397,  3258,  8305, 26123,     7,  6486,     6,  5177,\n",
       "            12,     6,    16,   346,    12,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [  123,   375,  5242,     5,    15,   564,  6282,   152,    15,\n",
       "           113,  5964,    16,     8,  3975,    19, 13197,  1971,    17,\n",
       "             0,  6491],\n",
       "        [  268,    46,     8,   426,    11,  3958,     0,     6,  3147,\n",
       "             0,     6, 22639,   688,     6,  6117, 11375,     6, 51567,\n",
       "         50982,     6],\n",
       "        [   43,     9,    79,  1250,    66,   931,  3399,   102,   405,\n",
       "            17,  8795,  2092,     0,    12,    87,    49,     8,  3399,\n",
       "            94,   102],\n",
       "        [    8, 10462,   113,    23,  1060,  4502,     7,     8,  2467,\n",
       "             9,  1202,    19,  4464,     7,   923,    11,   133,    16,\n",
       "           123,   489],\n",
       "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [  746,    58,     8,    81,   819, 14234,  1653,    11,   145,\n",
       "           127,   158,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [    8,  1382,  5090,  3067,   336,    89, 17528,   428,     5,\n",
       "           428,     5,   515,     9,   951,   430,    71,   189,  1103,\n",
       "           151,  1502],\n",
       "        [  106,  7342,    64,   172,   110,     6,   186, 24042,     6,\n",
       "           886,    23,    18,   857,   104,     6,  3351,    64,   172,\n",
       "           106,   359],\n",
       "        [    8,  1989,    23,   770,    64,     7,   617,    19, 13059,\n",
       "          8977,    20, 11161,  1909, 13233,    12,  1374,     6,    64,\n",
       "           819,     3],\n",
       "        [  306,  1128,   377,  2660,   362,  5533,  1080,    17,   647,\n",
       "         11177,    17,     8,   306,   877, 49368,  1118,    57, 24900,\n",
       "            16,   559],\n",
       "        [ 1244,  1159,    17,  1028,  4672,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1],\n",
       "        [   15,  7692,  3376, 10427,   847,    23,   305,    11,  1554,\n",
       "           123,  8523,  2092,    19,    15,   280,    18,  1182,     0,\n",
       "           108,    67]]),\n",
       " 'clicked_abs_pad': array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'clicked_vert': array([[100],\n",
       "        [  4],\n",
       "        [100],\n",
       "        [ 30],\n",
       "        [  4],\n",
       "        [169],\n",
       "        [  4],\n",
       "        [  3],\n",
       "        [  4],\n",
       "        [  4],\n",
       "        [ 31],\n",
       "        [  4],\n",
       "        [184],\n",
       "        [100],\n",
       "        [ 26],\n",
       "        [  4],\n",
       "        [ 88],\n",
       "        [169],\n",
       "        [  4],\n",
       "        [ 88],\n",
       "        [ 88],\n",
       "        [  3],\n",
       "        [ 31],\n",
       "        [169],\n",
       "        [184],\n",
       "        [ 21],\n",
       "        [  4],\n",
       "        [  3],\n",
       "        [  4],\n",
       "        [  4],\n",
       "        [  4],\n",
       "        [  4],\n",
       "        [184],\n",
       "        [ 88],\n",
       "        [ 21],\n",
       "        [  4],\n",
       "        [  4],\n",
       "        [169],\n",
       "        [  3],\n",
       "        [184],\n",
       "        [184],\n",
       "        [  3],\n",
       "        [  4],\n",
       "        [184],\n",
       "        [169],\n",
       "        [ 37],\n",
       "        [184],\n",
       "        [  4],\n",
       "        [ 45],\n",
       "        [  3]]),\n",
       " 'clicked_subvert': array([[  910],\n",
       "        [   14],\n",
       "        [  155],\n",
       "        [   76],\n",
       "        [   14],\n",
       "        [  955],\n",
       "        [   14],\n",
       "        [   34],\n",
       "        [   38],\n",
       "        [   38],\n",
       "        [  639],\n",
       "        [   41],\n",
       "        [ 1175],\n",
       "        [  155],\n",
       "        [   32],\n",
       "        [   41],\n",
       "        [  191],\n",
       "        [  955],\n",
       "        [   38],\n",
       "        [  500],\n",
       "        [  500],\n",
       "        [   13],\n",
       "        [ 1121],\n",
       "        [  955],\n",
       "        [ 1419],\n",
       "        [ 1414],\n",
       "        [45652],\n",
       "        [   63],\n",
       "        [   41],\n",
       "        [   41],\n",
       "        [   41],\n",
       "        [   48],\n",
       "        [  819],\n",
       "        [  191],\n",
       "        [ 1414],\n",
       "        [ 1970],\n",
       "        [   14],\n",
       "        [  955],\n",
       "        [   13],\n",
       "        [ 1175],\n",
       "        [  819],\n",
       "        [   63],\n",
       "        [   35],\n",
       "        [  819],\n",
       "        [  955],\n",
       "        [  918],\n",
       "        [ 1175],\n",
       "        [   41],\n",
       "        [  974],\n",
       "        [   34]]),\n",
       " 'his_mask': array([[False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]]),\n",
       " 'labels': array([1, 0, 0, 0, 0]),\n",
       " 'candidate_vert_onehot': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]]),\n",
       " 'clicked_vert_onehot': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]]),\n",
       " 'candidate_subvert_onehot': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'clicked_subvert_onehot': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])}"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "dataset.__getitem__(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2news = {v:k for k,v in dataset.nid2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'N3280'"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "id2news[13998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "dataset.vocab['mmaufc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'clicked_subvert_onehot' referenced before assignment",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-528b621a88c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-557bb49283e3>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mback_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clicked_vert_onehot'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclicked_vert_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mback_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candidate_subvert_onehot'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_subvert_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mback_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clicked_subvert_onehot'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclicked_subvert_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mback_dic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'clicked_subvert_onehot' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset, batch_size=5)\n",
    "list(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert2onehot = getId2idx(\n",
    "    'data/dictionaries/vert2onehot.json'\n",
    ")\n",
    "subvert2onehot = getId2idx(\n",
    "    'data/dictionaries/subvert2onehot.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvert2onehot['1'] = [0]*len(subvert2onehot['2513'])\n",
    "del subvert2onehot['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert2onehot['1'] = [0]*len(vert2onehot['138'])\n",
    "del vert2onehot['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'0'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-79607b1083af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvert2onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "vert2onehot['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['candidate_vert_onehot'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(dataset, batch_size=10, pin_memory=False, num_workers=0, drop_last=False, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(loader_train))['candidate_vert'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
    "\n",
    "\n",
    "def news_token_generator(news_file_list, tokenizer, attrs):\n",
    "    ''' merge and deduplicate training news and testing news then iterate, collect attrs into a single sentence and generate it\n",
    "\n",
    "    Args:\n",
    "        tokenizer: torchtext.data.utils.tokenizer\n",
    "        attrs: list of attrs to be collected and yielded\n",
    "    Returns:\n",
    "        a generator over attrs in news\n",
    "    '''\n",
    "    news_df_list = []\n",
    "    for f in news_file_list:\n",
    "        news_df_list.append(pd.read_table(f, index_col=None, names=[\n",
    "                            'newsID', 'category', 'subcategory', 'title', 'abstract', 'url', 'entity_title', 'entity_abstract'], quoting=3))\n",
    "\n",
    "    news_df = pd.concat(news_df_list).drop_duplicates()\n",
    "    news_iterator = news_df.iterrows()\n",
    "\n",
    "    for _, i in news_iterator:\n",
    "        content = []\n",
    "        for attr in attrs:\n",
    "            content.append(i[attr])\n",
    "\n",
    "        yield tokenizer(' '.join(content))\n",
    "\n",
    "\n",
    "def constructVocab(news_file_list, attrs):\n",
    "    \"\"\"\n",
    "        Build field using torchtext for tokenization\n",
    "\n",
    "    Returns:\n",
    "        torchtext.vocabulary\n",
    "    \"\"\"\n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        news_token_generator(news_file_list, tokenizer, attrs))\n",
    "\n",
    "    output = open(\n",
    "        'data/dictionaries/vocab_{}.pkl'.format(','.join(attrs)), 'wb')\n",
    "    pickle.dump(vocab, output)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "130379lines [00:19, 6580.66lines/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "attrs = ['title','category','subcategory']\n",
    "path= '/home/peitian_zhang/Data/MIND'\n",
    "scale = 'large'\n",
    "news_file_list = [path + '/MIND{}_train/news.tsv'.format(scale), path + '/MIND{}_dev/news.tsv'.format(scale), path + '/MIND{}_test/news.tsv'.format(scale)]\n",
    "constructVocab(news_file_list, attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = '/home/peitian_zhang/Data/MIND'\n",
    "news_file_list = [path + '/MINDlarge_train/news.tsv', path +\n",
    "                       '/MINDlarge_dev/news.tsv', path + '/MINDlarge_test/news.tsv']\n",
    "news_df_list = []\n",
    "for f in news_file_list:\n",
    "    news_df_list.append(pd.read_table(f, index_col=None, names=['newsID', 'category', 'subcategory', 'title', 'abstract', 'url', 'entity_title', 'entity_abstract'], quoting=3))\n",
    "\n",
    "news_df = pd.concat(news_df_list).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert = news_df['category'].unique()\n",
    "subvert = news_df['subcategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "len(subvert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in subvert:\n",
    "    if (tokenize(i, dataset.vocab)) == [0]:\n",
    "        print(\"fuck\")\n",
    "    if dataset.vocab[i] == 0:\n",
    "        print(\"fuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert,subvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8409"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "vocab['basketball_nba_videos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import getVocab,tokenize\n",
    "vocab = getVocab('data/dictionaries/vocab_whole.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({30: 0,\n",
       "  3: 1,\n",
       "  37: 2,\n",
       "  4: 3,\n",
       "  26: 4,\n",
       "  184: 5,\n",
       "  31: 6,\n",
       "  45: 7,\n",
       "  24: 8,\n",
       "  22: 9,\n",
       "  21: 10,\n",
       "  88: 11,\n",
       "  169: 12,\n",
       "  100: 13,\n",
       "  321: 14,\n",
       "  29067: 15,\n",
       "  316: 16,\n",
       "  46539: 17},\n",
       " {771: 0,\n",
       "  47: 1,\n",
       "  1295: 2,\n",
       "  126: 3,\n",
       "  63: 4,\n",
       "  897: 5,\n",
       "  10067: 6,\n",
       "  14: 7,\n",
       "  32: 8,\n",
       "  618: 9,\n",
       "  195: 10,\n",
       "  5340: 11,\n",
       "  700: 12,\n",
       "  633: 13,\n",
       "  2627: 14,\n",
       "  258: 15,\n",
       "  287: 16,\n",
       "  819: 17,\n",
       "  52: 18,\n",
       "  2679: 19,\n",
       "  25: 20,\n",
       "  48: 21,\n",
       "  684: 22,\n",
       "  409: 23,\n",
       "  90: 24,\n",
       "  1317: 25,\n",
       "  146: 26,\n",
       "  50: 27,\n",
       "  1755: 28,\n",
       "  3685: 29,\n",
       "  35: 30,\n",
       "  76: 31,\n",
       "  141: 32,\n",
       "  918: 33,\n",
       "  13: 34,\n",
       "  2427: 35,\n",
       "  191: 36,\n",
       "  1754: 37,\n",
       "  41: 38,\n",
       "  3: 39,\n",
       "  3705: 40,\n",
       "  6138: 41,\n",
       "  2638: 42,\n",
       "  77: 43,\n",
       "  82: 44,\n",
       "  115: 45,\n",
       "  3146: 46,\n",
       "  500: 47,\n",
       "  74: 48,\n",
       "  2910: 49,\n",
       "  2452: 50,\n",
       "  175: 51,\n",
       "  642: 52,\n",
       "  38: 53,\n",
       "  155: 54,\n",
       "  3121: 55,\n",
       "  6160: 56,\n",
       "  4449: 57,\n",
       "  1555: 58,\n",
       "  558: 59,\n",
       "  1878: 60,\n",
       "  1121: 61,\n",
       "  1724: 62,\n",
       "  182: 63,\n",
       "  462: 64,\n",
       "  3249: 65,\n",
       "  639: 66,\n",
       "  6411: 67,\n",
       "  2909: 68,\n",
       "  556: 69,\n",
       "  216: 70,\n",
       "  34: 71,\n",
       "  2067: 72,\n",
       "  8573: 73,\n",
       "  1411: 74,\n",
       "  974: 75,\n",
       "  2047: 76,\n",
       "  50190: 77,\n",
       "  5405: 78,\n",
       "  5938: 79,\n",
       "  1419: 80,\n",
       "  1108: 81,\n",
       "  1043: 82,\n",
       "  4816: 83,\n",
       "  885: 84,\n",
       "  10014: 85,\n",
       "  1414: 86,\n",
       "  961: 87,\n",
       "  2950: 88,\n",
       "  8544: 89,\n",
       "  1047: 90,\n",
       "  8402: 91,\n",
       "  156: 92,\n",
       "  4186: 93,\n",
       "  527: 94,\n",
       "  1278: 95,\n",
       "  963: 96,\n",
       "  7765: 97,\n",
       "  2612: 98,\n",
       "  342: 99,\n",
       "  1436: 100,\n",
       "  96: 101,\n",
       "  5441: 102,\n",
       "  2345: 103,\n",
       "  864: 104,\n",
       "  955: 105,\n",
       "  6938: 106,\n",
       "  4411: 107,\n",
       "  2724: 108,\n",
       "  7951: 109,\n",
       "  1507: 110,\n",
       "  2085: 111,\n",
       "  12670: 112,\n",
       "  4488: 113,\n",
       "  3260: 114,\n",
       "  1175: 115,\n",
       "  1872: 116,\n",
       "  6603: 117,\n",
       "  3753: 118,\n",
       "  459: 119,\n",
       "  27895: 120,\n",
       "  22: 121,\n",
       "  1593: 122,\n",
       "  4216: 123,\n",
       "  3780: 124,\n",
       "  10608: 125,\n",
       "  5543: 126,\n",
       "  3831: 127,\n",
       "  7661: 128,\n",
       "  910: 129,\n",
       "  30: 130,\n",
       "  3672: 131,\n",
       "  7662: 132,\n",
       "  728: 133,\n",
       "  385: 134,\n",
       "  24308: 135,\n",
       "  3572: 136,\n",
       "  521: 137,\n",
       "  4958: 138,\n",
       "  28701: 139,\n",
       "  12433: 140,\n",
       "  12013: 141,\n",
       "  6606: 142,\n",
       "  9484: 143,\n",
       "  3981: 144,\n",
       "  1826: 145,\n",
       "  14870: 146,\n",
       "  6692: 147,\n",
       "  1233: 148,\n",
       "  1970: 149,\n",
       "  1239: 150,\n",
       "  1135: 151,\n",
       "  1823: 152,\n",
       "  1911: 153,\n",
       "  15236: 154,\n",
       "  5829: 155,\n",
       "  1486: 156,\n",
       "  8840: 157,\n",
       "  4416: 158,\n",
       "  5370: 159,\n",
       "  1703: 160,\n",
       "  5150: 161,\n",
       "  6325: 162,\n",
       "  11891: 163,\n",
       "  3869: 164,\n",
       "  21119: 165,\n",
       "  18873: 166,\n",
       "  8127: 167,\n",
       "  22798: 168,\n",
       "  3411: 169,\n",
       "  19448: 170,\n",
       "  40393: 171,\n",
       "  8753: 172,\n",
       "  50620: 173,\n",
       "  13953: 174,\n",
       "  316: 175,\n",
       "  6633: 176,\n",
       "  14970: 177,\n",
       "  25661: 178,\n",
       "  14233: 179,\n",
       "  10451: 180,\n",
       "  114: 181,\n",
       "  12493: 182,\n",
       "  30741: 183,\n",
       "  26252: 184,\n",
       "  13675: 185,\n",
       "  805: 186,\n",
       "  7219: 187,\n",
       "  26242: 188,\n",
       "  7434: 189,\n",
       "  44340: 190,\n",
       "  44339: 191,\n",
       "  14245: 192,\n",
       "  40396: 193,\n",
       "  7312: 194,\n",
       "  4: 195,\n",
       "  18525: 196,\n",
       "  7438: 197,\n",
       "  3920: 198,\n",
       "  6351: 199,\n",
       "  35190: 200,\n",
       "  35189: 201,\n",
       "  52379: 202,\n",
       "  9231: 203,\n",
       "  11154: 204,\n",
       "  40395: 205,\n",
       "  46817: 206,\n",
       "  588: 207,\n",
       "  27682: 208,\n",
       "  35193: 209,\n",
       "  5016: 210,\n",
       "  12661: 211,\n",
       "  50531: 212,\n",
       "  46294: 213,\n",
       "  14522: 214,\n",
       "  27301: 215,\n",
       "  29068: 216,\n",
       "  21450: 217,\n",
       "  3565: 218,\n",
       "  46301: 219,\n",
       "  42045: 220,\n",
       "  17298: 221,\n",
       "  427: 222,\n",
       "  352: 223,\n",
       "  45535: 224,\n",
       "  37850: 225,\n",
       "  8409: 226,\n",
       "  45652: 227,\n",
       "  24352: 228,\n",
       "  46120: 229,\n",
       "  40394: 230,\n",
       "  88: 231,\n",
       "  2770: 232,\n",
       "  41049: 233,\n",
       "  29368: 234,\n",
       "  185: 235,\n",
       "  10294: 236,\n",
       "  9564: 237,\n",
       "  37691: 238,\n",
       "  14263: 239,\n",
       "  46998: 240,\n",
       "  24619: 241,\n",
       "  46299: 242,\n",
       "  44342: 243,\n",
       "  4515: 244,\n",
       "  4783: 245,\n",
       "  2866: 246,\n",
       "  15598: 247,\n",
       "  4691: 248,\n",
       "  24: 249,\n",
       "  1038: 250,\n",
       "  31408: 251,\n",
       "  46297: 252,\n",
       "  40647: 253,\n",
       "  20444: 254,\n",
       "  14969: 255,\n",
       "  40392: 256,\n",
       "  53536: 257,\n",
       "  36960: 258,\n",
       "  46302: 259,\n",
       "  28198: 260,\n",
       "  42049: 261,\n",
       "  28702: 262,\n",
       "  44343: 263,\n",
       "  30740: 264,\n",
       "  42040: 265,\n",
       "  44341: 266,\n",
       "  4731: 267,\n",
       "  40397: 268,\n",
       "  50810: 269,\n",
       "  9492: 270,\n",
       "  222: 271,\n",
       "  9726: 272,\n",
       "  52387: 273,\n",
       "  50618: 274,\n",
       "  52590: 275,\n",
       "  31: 276,\n",
       "  31291: 277,\n",
       "  39656: 278,\n",
       "  46540: 279,\n",
       "  35191: 280,\n",
       "  50619: 281,\n",
       "  39657: 282,\n",
       "  9560: 283,\n",
       "  37017: 284,\n",
       "  36959: 285,\n",
       "  2112: 286,\n",
       "  46902: 287,\n",
       "  49853: 288,\n",
       "  41495: 289,\n",
       "  42046: 290,\n",
       "  44468: 291,\n",
       "  40649: 292})"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "vert2idx = {\n",
    "    vocab[v]:i for i,v in enumerate(vert)\n",
    "}\n",
    "subvert2idx = {\n",
    "    vocab[v]:i for i,v in enumerate(subvert)\n",
    "}\n",
    "vert2idx, subvert2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'lifestyle'"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "vocab.itos[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{771: 0,\n",
       " 47: 1,\n",
       " 1295: 2,\n",
       " 126: 3,\n",
       " 63: 4,\n",
       " 897: 5,\n",
       " 10067: 6,\n",
       " 14: 7,\n",
       " 32: 8,\n",
       " 618: 9,\n",
       " 195: 10,\n",
       " 5340: 11,\n",
       " 700: 12,\n",
       " 633: 13,\n",
       " 2627: 14,\n",
       " 258: 15,\n",
       " 287: 16,\n",
       " 819: 17,\n",
       " 52: 18,\n",
       " 2679: 19,\n",
       " 25: 20,\n",
       " 48: 21,\n",
       " 684: 22,\n",
       " 409: 23,\n",
       " 90: 24,\n",
       " 1317: 25,\n",
       " 146: 26,\n",
       " 50: 27,\n",
       " 1755: 28,\n",
       " 3685: 29,\n",
       " 35: 30,\n",
       " 76: 31,\n",
       " 141: 32,\n",
       " 918: 33,\n",
       " 13: 34,\n",
       " 2427: 35,\n",
       " 191: 36,\n",
       " 1754: 37,\n",
       " 41: 38,\n",
       " 3: 39,\n",
       " 3705: 40,\n",
       " 6138: 41,\n",
       " 2638: 42,\n",
       " 77: 43,\n",
       " 82: 44,\n",
       " 115: 45,\n",
       " 3146: 46,\n",
       " 500: 47,\n",
       " 74: 48,\n",
       " 2910: 49,\n",
       " 2452: 50,\n",
       " 175: 51,\n",
       " 642: 52,\n",
       " 38: 53,\n",
       " 155: 54,\n",
       " 3121: 55,\n",
       " 6160: 56,\n",
       " 4449: 57,\n",
       " 1555: 58,\n",
       " 558: 59,\n",
       " 1878: 60,\n",
       " 1121: 61,\n",
       " 1724: 62,\n",
       " 182: 63,\n",
       " 462: 64,\n",
       " 3249: 65,\n",
       " 639: 66,\n",
       " 6411: 67,\n",
       " 2909: 68,\n",
       " 556: 69,\n",
       " 216: 70,\n",
       " 34: 71,\n",
       " 2067: 72,\n",
       " 8573: 73,\n",
       " 1411: 74,\n",
       " 974: 75,\n",
       " 2047: 76,\n",
       " 50190: 77,\n",
       " 5405: 78,\n",
       " 5938: 79,\n",
       " 1419: 80,\n",
       " 1108: 81,\n",
       " 1043: 82,\n",
       " 4816: 83,\n",
       " 885: 84,\n",
       " 10014: 85,\n",
       " 1414: 86,\n",
       " 961: 87,\n",
       " 2950: 88,\n",
       " 8544: 89,\n",
       " 1047: 90,\n",
       " 8402: 91,\n",
       " 156: 92,\n",
       " 4186: 93,\n",
       " 527: 94,\n",
       " 1278: 95,\n",
       " 963: 96,\n",
       " 7765: 97,\n",
       " 2612: 98,\n",
       " 342: 99,\n",
       " 1436: 100,\n",
       " 96: 101,\n",
       " 5441: 102,\n",
       " 2345: 103,\n",
       " 864: 104,\n",
       " 955: 105,\n",
       " 6938: 106,\n",
       " 4411: 107,\n",
       " 2724: 108,\n",
       " 7951: 109,\n",
       " 1507: 110,\n",
       " 2085: 111,\n",
       " 12670: 112,\n",
       " 4488: 113,\n",
       " 3260: 114,\n",
       " 1175: 115,\n",
       " 1872: 116,\n",
       " 6603: 117,\n",
       " 3753: 118,\n",
       " 459: 119,\n",
       " 27895: 120,\n",
       " 22: 121,\n",
       " 1593: 122,\n",
       " 4216: 123,\n",
       " 3780: 124,\n",
       " 10608: 125,\n",
       " 5543: 126,\n",
       " 3831: 127,\n",
       " 7661: 128,\n",
       " 910: 129,\n",
       " 30: 130,\n",
       " 3672: 131,\n",
       " 7662: 132,\n",
       " 728: 133,\n",
       " 385: 134,\n",
       " 24308: 135,\n",
       " 3572: 136,\n",
       " 521: 137,\n",
       " 4958: 138,\n",
       " 28701: 139,\n",
       " 12433: 140,\n",
       " 12013: 141,\n",
       " 6606: 142,\n",
       " 9484: 143,\n",
       " 3981: 144,\n",
       " 1826: 145,\n",
       " 14870: 146,\n",
       " 6692: 147,\n",
       " 1233: 148,\n",
       " 1970: 149,\n",
       " 1239: 150,\n",
       " 1135: 151,\n",
       " 1823: 152,\n",
       " 1911: 153,\n",
       " 15236: 154,\n",
       " 5829: 155,\n",
       " 1486: 156,\n",
       " 8840: 157,\n",
       " 4416: 158,\n",
       " 5370: 159,\n",
       " 1703: 160,\n",
       " 5150: 161,\n",
       " 6325: 162,\n",
       " 11891: 163,\n",
       " 3869: 164,\n",
       " 21119: 165,\n",
       " 18873: 166,\n",
       " 8127: 167,\n",
       " 22798: 168,\n",
       " 3411: 169,\n",
       " 19448: 170,\n",
       " 40393: 171,\n",
       " 8753: 172,\n",
       " 50620: 173,\n",
       " 13953: 174,\n",
       " 316: 175,\n",
       " 6633: 176,\n",
       " 14970: 177,\n",
       " 25661: 178,\n",
       " 14233: 179,\n",
       " 10451: 180,\n",
       " 114: 181,\n",
       " 12493: 182,\n",
       " 30741: 183,\n",
       " 26252: 184,\n",
       " 13675: 185,\n",
       " 805: 186,\n",
       " 7219: 187,\n",
       " 26242: 188,\n",
       " 7434: 189,\n",
       " 44340: 190,\n",
       " 44339: 191,\n",
       " 14245: 192,\n",
       " 40396: 193,\n",
       " 7312: 194,\n",
       " 4: 195,\n",
       " 18525: 196,\n",
       " 7438: 197,\n",
       " 3920: 198,\n",
       " 6351: 199,\n",
       " 35190: 200,\n",
       " 35189: 201,\n",
       " 52379: 202,\n",
       " 9231: 203,\n",
       " 11154: 204,\n",
       " 40395: 205,\n",
       " 46817: 206,\n",
       " 588: 207,\n",
       " 27682: 208,\n",
       " 35193: 209,\n",
       " 5016: 210,\n",
       " 12661: 211,\n",
       " 50531: 212,\n",
       " 46294: 213,\n",
       " 14522: 214,\n",
       " 27301: 215,\n",
       " 29068: 216,\n",
       " 21450: 217,\n",
       " 3565: 218,\n",
       " 46301: 219,\n",
       " 42045: 220,\n",
       " 17298: 221,\n",
       " 427: 222,\n",
       " 352: 223,\n",
       " 45535: 224,\n",
       " 37850: 225,\n",
       " 8409: 226,\n",
       " 45652: 227,\n",
       " 24352: 228,\n",
       " 46120: 229,\n",
       " 40394: 230,\n",
       " 88: 231,\n",
       " 2770: 232,\n",
       " 41049: 233,\n",
       " 29368: 234,\n",
       " 185: 235,\n",
       " 10294: 236,\n",
       " 9564: 237,\n",
       " 37691: 238,\n",
       " 14263: 239,\n",
       " 46998: 240,\n",
       " 24619: 241,\n",
       " 46299: 242,\n",
       " 44342: 243,\n",
       " 4515: 244,\n",
       " 4783: 245,\n",
       " 2866: 246,\n",
       " 15598: 247,\n",
       " 4691: 248,\n",
       " 24: 249,\n",
       " 1038: 250,\n",
       " 31408: 251,\n",
       " 46297: 252,\n",
       " 40647: 253,\n",
       " 20444: 254,\n",
       " 14969: 255,\n",
       " 40392: 256,\n",
       " 53536: 257,\n",
       " 36960: 258,\n",
       " 46302: 259,\n",
       " 28198: 260,\n",
       " 42049: 261,\n",
       " 28702: 262,\n",
       " 44343: 263,\n",
       " 30740: 264,\n",
       " 42040: 265,\n",
       " 44341: 266,\n",
       " 4731: 267,\n",
       " 40397: 268,\n",
       " 50810: 269,\n",
       " 9492: 270,\n",
       " 222: 271,\n",
       " 9726: 272,\n",
       " 52387: 273,\n",
       " 50618: 274,\n",
       " 52590: 275,\n",
       " 31: 276,\n",
       " 31291: 277,\n",
       " 39656: 278,\n",
       " 46540: 279,\n",
       " 35191: 280,\n",
       " 50619: 281,\n",
       " 39657: 282,\n",
       " 9560: 283,\n",
       " 37017: 284,\n",
       " 36959: 285,\n",
       " 2112: 286,\n",
       " 46902: 287,\n",
       " 49853: 288,\n",
       " 41495: 289,\n",
       " 42046: 290,\n",
       " 44468: 291,\n",
       " 40649: 292}"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "subvert2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'lifestyleroyals'"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "vocab.itos[771]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vert2onehot = {}\n",
    "for k,v in vert2idx.items():\n",
    "    a = np.zeros((len(vert2idx)))\n",
    "    index = np.asarray([v])\n",
    "    a[index] = 1\n",
    "    vert2onehot[int(k)] = a.tolist()\n",
    "vert2onehot[1] = [0]*len(vert2onehot[30])\n",
    "\n",
    "subvert2onehot = {}\n",
    "for k,v in subvert2idx.items():\n",
    "    a = np.zeros((len(subvert2idx)))\n",
    "    index = np.asarray([v])\n",
    "    a[index] = 1\n",
    "    subvert2onehot[int(k)] = a.tolist()\n",
    "subvert2onehot[1] = [0]*len(subvert2onehot[771])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "subvert2onehot[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(vert2onehot, open('data/dictionaries/vert2onehot.json','w'),ensure_ascii=False)\n",
    "json.dump(subvert2onehot, open('data/dictionaries/subvert2onehot.json','w'),ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}