{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnncondad67fb259925d4833a703b0467175fd55",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3eb98a31bb4fe483f921d6d3a56a708e0ea8295072fddff1b0a8d949ab7fd102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from utils.utils import prepare,analyse,constructBasicDict,tailorData\n",
    "from configs.ManualConfig import hparams"
   ]
  },
  {
   "source": [
    "### Construct necessary dictionaries\n",
    "- already done and the results are in `data/dictionaries`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructBasicDict(attrs=['title'],path='/home/peitian_zhang/Data/MIND')"
   ]
  },
  {
   "source": [
    "### View data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-04-21 07:14:08,513] INFO (root) Hyper Parameters are\n",
      "{'scale': 'demo', 'mode': 'train', 'batch_size': 10, 'title_size': 20, 'abs_size': 40, 'his_size': 30, 'vert_num': 18, 'subvert_num': 293, 'npratio': 4, 'dropout_p': 0.2, 'query_dim': 200, 'embedding_dim': 300, 'filter_num': 150, 'value_dim': 16, 'head_num': 16, 'epochs': 8, 'metrics': 'auc,mean_mrr,ndcg@5,ndcg@10', 'device': 'cpu', 'attrs': ['title'], 'k': 0, 'select': None, 'save_step': [0], 'news_id': False, 'validate': False, 'interval': 10, 'spadam': True, 'onehot': False, 'val_freq': 1, 'schedule': None}\n",
      "[2021-04-21 07:14:08,626] INFO (root) preparing dataset...\n",
      "[2021-04-21 07:14:12,527] INFO (torchtext.vocab) Loading vectors from .vector_cache/glove.840B.300d.txt.pt\n"
     ]
    }
   ],
   "source": [
    "vocab, loaders = prepare(hparams, pin_memory=False)\n",
    "\n",
    "# for encoding news only\n",
    "# vocab, loaders = prepare(hparams, news=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader_train\n",
    "a = next(iter(loaders[0]))\n",
    "# loader_dev\n",
    "b = next(iter(loaders[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'impression_index': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'user_index': tensor([[1929],\n",
       "         [1929],\n",
       "         [1929],\n",
       "         [1929],\n",
       "         [1929],\n",
       "         [1929],\n",
       "         [1929],\n",
       "         [1929],\n",
       "         [1929],\n",
       "         [1929]]),\n",
       " 'cdd_id': tensor([[36180],\n",
       "         [41328],\n",
       "         [41034],\n",
       "         [39776],\n",
       "         [34983],\n",
       "         [37322],\n",
       "         [37327],\n",
       "         [36307],\n",
       "         [36185],\n",
       "         [36349]]),\n",
       " 'candidate_title': tensor([[[    1,     1,     1,     1,     1,     1,     1,     1,   255,  9098,\n",
       "               5,  1290,  1482,     6,   314,  1087,   851,     9,  3812,  7065]],\n",
       " \n",
       "         [[  106,   834,   400,  6330,    75,  2025,   480,    10,    15,   157,\n",
       "              17,   776,  3228,   104,  4912,     7,    15, 33313,    95,     5]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,  1064,  1273,\n",
       "            1253,    23,    75,     5,    83,    46,    91,  4247,    15,   950]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     8, 19345,\n",
       "             412,  2957,    53, 13028,   163,   260,   271,     7, 17119,  6888]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,   998,    17,\n",
       "             120,    46,   145,    70,   706,  7087,   758,    49,  1514,   177]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,    97,    62,   793,   113,     9,\n",
       "             189,    20,   808,   341, 17258, 13189,  1613,   133,     5,   413]],\n",
       " \n",
       "         [[    1,     1,     1,     1,   161,    12,     9,    12,  1824,    39,\n",
       "            1784,   228,   162,  1218,     7,   498,     6, 25757, 25402,  1242]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,   110,   596,  5106,  1304,    20,\n",
       "              15,   200,    11,  3892,  1647,    99,    15,   270,  3521,  3960]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,  8151,\n",
       "            7271,   546,    51,  2299,  4705,   152,  1925,   119,    54,    27]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,  5862,\n",
       "             781,  2931,    67,   132,  1035,    16,   263,     5,  2287,   309]]]),\n",
       " 'candidate_title_pad': tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]),\n",
       " 'candidate_abs': tensor([[[    1,     1,     1,     1,     1,     1,   317,  4059,  2962,   143,\n",
       "            3936,   202, 26441,    16,   123,  1114,   224,     8,   112,   131,\n",
       "            2508,   431,     6,   119,     8,  6400,  1768,    29,  1740,    17,\n",
       "             976,  3589,   197,    54,  1214,   851,  7584,     8,   396,    12]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,   106,  7744,     7,    15,  2025,   130,    10,\n",
       "             322,   620,     5,   268,    46,     8, 27550,   103,   145,    75,\n",
       "               6,    17,   106,   103,  2922,    51,    46,   106,  2508,    12]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     8,   332,   215,    56,   214,\n",
       "              10,     8,  3611,  8302,    11,  1273,  1253,    33,     8,  1240,\n",
       "              23,  3924,     5,   330,    58,    10,   403,    16,   492,    12]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,  3033,     9,   412,  2957,    53,   163,   260,   271]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,   176,     0,    17,   724,  3248,   401,\n",
       "               8, 14746,   112,    11,     8,    81,  2630,    11,     8,  2356,\n",
       "              12,    87,     9,    46,   162,   310,    69,     5,   120,    12]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,    62,    49,   793,   123,  3765,\n",
       "               0,   189,    11,    15,   113,    20,     8,   808, 17258, 13189,\n",
       "            1613,   133,     5,    15,   413,     6,  1037,     5,   936,    12]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,   210,  1048,    40,    89,\n",
       "             964,    15,  1016,    11,  1237,    39,  1218,     7,     8,   374,\n",
       "              11,     8,   576,     5,   855,     8,  1051,  3897,   392,    12]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             930,   212,   162,   436,     5,  2167,   123, 15153,  1014,     7,\n",
       "            1107,     6,   322,  5106,  1149,    58,  3892,    10,    15,  1988,\n",
       "             930,    17,  4887,     5,  1683,     5,    15,  4432,  4263,    12]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,    15,  5640,    11,   735,  8151,  4964,     5,   102,\n",
       "             400,  7271,   546,    51,     8,   454,  2543,    29,  2299,  4705,\n",
       "             102,   400,   152,    16,    15,  3041,   725,     7,   204,   634]],\n",
       " \n",
       "         [[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,    46,   178,   102,   400,    15,\n",
       "            3540,   431,     0,    99,    15,  3497,    10,   288,    17,   896,\n",
       "              18,  3385,   108,    67,     7,   781,  2931,     6,   170,    12]]]),\n",
       " 'candidate_abs_pad': tensor([[[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " \n",
       "         [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]),\n",
       " 'candidate_vert': tensor([[[  4]],\n",
       " \n",
       "         [[ 30]],\n",
       " \n",
       "         [[  4]],\n",
       " \n",
       "         [[ 88]],\n",
       " \n",
       "         [[184]],\n",
       " \n",
       "         [[  4]],\n",
       " \n",
       "         [[  3]],\n",
       " \n",
       "         [[  3]],\n",
       " \n",
       "         [[ 30]],\n",
       " \n",
       "         [[  3]]]),\n",
       " 'candidate_subvert': tensor([[[ 14]],\n",
       " \n",
       "         [[897]],\n",
       " \n",
       "         [[ 14]],\n",
       " \n",
       "         [[500]],\n",
       " \n",
       "         [[819]],\n",
       " \n",
       "         [[ 14]],\n",
       " \n",
       "         [[ 63]],\n",
       " \n",
       "         [[ 13]],\n",
       " \n",
       "         [[ 76]],\n",
       " \n",
       "         [[ 13]]]),\n",
       " 'his_id': tensor([[ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'clicked_title': tensor([[[    1,     1,     1,  ...,     8,  7229, 13032],\n",
       "          [    1,     1,     1,  ...,  9665,  2460,     7],\n",
       "          [    1,     1,     1,  ...,   194,  3434,  1973],\n",
       "          ...,\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1]],\n",
       " \n",
       "         [[    1,     1,     1,  ...,     8,  7229, 13032],\n",
       "          [    1,     1,     1,  ...,  9665,  2460,     7],\n",
       "          [    1,     1,     1,  ...,   194,  3434,  1973],\n",
       "          ...,\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1]],\n",
       " \n",
       "         [[    1,     1,     1,  ...,     8,  7229, 13032],\n",
       "          [    1,     1,     1,  ...,  9665,  2460,     7],\n",
       "          [    1,     1,     1,  ...,   194,  3434,  1973],\n",
       "          ...,\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[    1,     1,     1,  ...,     8,  7229, 13032],\n",
       "          [    1,     1,     1,  ...,  9665,  2460,     7],\n",
       "          [    1,     1,     1,  ...,   194,  3434,  1973],\n",
       "          ...,\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1]],\n",
       " \n",
       "         [[    1,     1,     1,  ...,     8,  7229, 13032],\n",
       "          [    1,     1,     1,  ...,  9665,  2460,     7],\n",
       "          [    1,     1,     1,  ...,   194,  3434,  1973],\n",
       "          ...,\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1]],\n",
       " \n",
       "         [[    1,     1,     1,  ...,     8,  7229, 13032],\n",
       "          [    1,     1,     1,  ...,  9665,  2460,     7],\n",
       "          [    1,     1,     1,  ...,   194,  3434,  1973],\n",
       "          ...,\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1]]]),\n",
       " 'clicked_title_pad': tensor([[[0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]]),\n",
       " 'clicked_abs': tensor([[[ 131,  439,  224,  ..., 1164,   12,  202],\n",
       "          [   1,    1,    1,  ...,  116,  102, 1726],\n",
       "          [   1,    1,    1,  ...,  304, 1004,   12],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]],\n",
       " \n",
       "         [[ 131,  439,  224,  ..., 1164,   12,  202],\n",
       "          [   1,    1,    1,  ...,  116,  102, 1726],\n",
       "          [   1,    1,    1,  ...,  304, 1004,   12],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]],\n",
       " \n",
       "         [[ 131,  439,  224,  ..., 1164,   12,  202],\n",
       "          [   1,    1,    1,  ...,  116,  102, 1726],\n",
       "          [   1,    1,    1,  ...,  304, 1004,   12],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 131,  439,  224,  ..., 1164,   12,  202],\n",
       "          [   1,    1,    1,  ...,  116,  102, 1726],\n",
       "          [   1,    1,    1,  ...,  304, 1004,   12],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]],\n",
       " \n",
       "         [[ 131,  439,  224,  ..., 1164,   12,  202],\n",
       "          [   1,    1,    1,  ...,  116,  102, 1726],\n",
       "          [   1,    1,    1,  ...,  304, 1004,   12],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]],\n",
       " \n",
       "         [[ 131,  439,  224,  ..., 1164,   12,  202],\n",
       "          [   1,    1,    1,  ...,  116,  102, 1726],\n",
       "          [   1,    1,    1,  ...,  304, 1004,   12],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]]]),\n",
       " 'clicked_abs_pad': tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          [0, 0, 0,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]]),\n",
       " 'clicked_vert': tensor([[[ 88],\n",
       "          [  3],\n",
       "          [ 88],\n",
       "          [  3],\n",
       "          [ 21],\n",
       "          [ 45],\n",
       "          [ 88],\n",
       "          [169],\n",
       "          [184],\n",
       "          [  3],\n",
       "          [ 30],\n",
       "          [  3],\n",
       "          [  3],\n",
       "          [ 37],\n",
       "          [ 88],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1]],\n",
       " \n",
       "         [[ 88],\n",
       "          [  3],\n",
       "          [ 88],\n",
       "          [  3],\n",
       "          [ 21],\n",
       "          [ 45],\n",
       "          [ 88],\n",
       "          [169],\n",
       "          [184],\n",
       "          [  3],\n",
       "          [ 30],\n",
       "          [  3],\n",
       "          [  3],\n",
       "          [ 37],\n",
       "          [ 88],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1]],\n",
       " \n",
       "         [[ 88],\n",
       "          [  3],\n",
       "          [ 88],\n",
       "          [  3],\n",
       "          [ 21],\n",
       "          [ 45],\n",
       "          [ 88],\n",
       "          [169],\n",
       "          [184],\n",
       "          [  3],\n",
       "          [ 30],\n",
       "          [  3],\n",
       "          [  3],\n",
       "          [ 37],\n",
       "          [ 88],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1]],\n",
       " \n",
       "         [[ 88],\n",
       "          [  3],\n",
       "          [ 88],\n",
       "          [  3],\n",
       "          [ 21],\n",
       "          [ 45],\n",
       "          [ 88],\n",
       "          [169],\n",
       "          [184],\n",
       "          [  3],\n",
       "          [ 30],\n",
       "          [  3],\n",
       "          [  3],\n",
       "          [ 37],\n",
       "          [ 88],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1]],\n",
       " \n",
       "         [[ 88],\n",
       "          [  3],\n",
       "          [ 88],\n",
       "          [  3],\n",
       "          [ 21],\n",
       "          [ 45],\n",
       "          [ 88],\n",
       "          [169],\n",
       "          [184],\n",
       "          [  3],\n",
       "          [ 30],\n",
       "          [  3],\n",
       "          [  3],\n",
       "          [ 37],\n",
       "          [ 88],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1]],\n",
       " \n",
       "         [[ 88],\n",
       "          [  3],\n",
       "          [ 88],\n",
       "          [  3],\n",
       "          [ 21],\n",
       "          [ 45],\n",
       "          [ 88],\n",
       "          [169],\n",
       "          [184],\n",
       "          [  3],\n",
       "          [ 30],\n",
       "          [  3],\n",
       "          [  3],\n",
       "          [ 37],\n",
       "          [ 88],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1]],\n",
       " \n",
       "         [[ 88],\n",
       "          [  3],\n",
       "          [ 88],\n",
       "          [  3],\n",
       "          [ 21],\n",
       "          [ 45],\n",
       "          [ 88],\n",
       "          [169],\n",
       "          [184],\n",
       "          [  3],\n",
       "          [ 30],\n",
       "          [  3],\n",
       "          [  3],\n",
       "          [ 37],\n",
       "          [ 88],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1]],\n",
       " \n",
       "         [[ 88],\n",
       "          [  3],\n",
       "          [ 88],\n",
       "          [  3],\n",
       "          [ 21],\n",
       "          [ 45],\n",
       "          [ 88],\n",
       "          [169],\n",
       "          [184],\n",
       "          [  3],\n",
       "          [ 30],\n",
       "          [  3],\n",
       "          [  3],\n",
       "          [ 37],\n",
       "          [ 88],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1]],\n",
       " \n",
       "         [[ 88],\n",
       "          [  3],\n",
       "          [ 88],\n",
       "          [  3],\n",
       "          [ 21],\n",
       "          [ 45],\n",
       "          [ 88],\n",
       "          [169],\n",
       "          [184],\n",
       "          [  3],\n",
       "          [ 30],\n",
       "          [  3],\n",
       "          [  3],\n",
       "          [ 37],\n",
       "          [ 88],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1]],\n",
       " \n",
       "         [[ 88],\n",
       "          [  3],\n",
       "          [ 88],\n",
       "          [  3],\n",
       "          [ 21],\n",
       "          [ 45],\n",
       "          [ 88],\n",
       "          [169],\n",
       "          [184],\n",
       "          [  3],\n",
       "          [ 30],\n",
       "          [  3],\n",
       "          [  3],\n",
       "          [ 37],\n",
       "          [ 88],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1],\n",
       "          [  1]]]),\n",
       " 'clicked_subvert': tensor([[[ 191],\n",
       "          [  13],\n",
       "          [ 500],\n",
       "          [  13],\n",
       "          [ 216],\n",
       "          [ 633],\n",
       "          [ 500],\n",
       "          [ 955],\n",
       "          [1175],\n",
       "          [  34],\n",
       "          [ 771],\n",
       "          [  13],\n",
       "          [  25],\n",
       "          [ 918],\n",
       "          [ 191],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1]],\n",
       " \n",
       "         [[ 191],\n",
       "          [  13],\n",
       "          [ 500],\n",
       "          [  13],\n",
       "          [ 216],\n",
       "          [ 633],\n",
       "          [ 500],\n",
       "          [ 955],\n",
       "          [1175],\n",
       "          [  34],\n",
       "          [ 771],\n",
       "          [  13],\n",
       "          [  25],\n",
       "          [ 918],\n",
       "          [ 191],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1]],\n",
       " \n",
       "         [[ 191],\n",
       "          [  13],\n",
       "          [ 500],\n",
       "          [  13],\n",
       "          [ 216],\n",
       "          [ 633],\n",
       "          [ 500],\n",
       "          [ 955],\n",
       "          [1175],\n",
       "          [  34],\n",
       "          [ 771],\n",
       "          [  13],\n",
       "          [  25],\n",
       "          [ 918],\n",
       "          [ 191],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1]],\n",
       " \n",
       "         [[ 191],\n",
       "          [  13],\n",
       "          [ 500],\n",
       "          [  13],\n",
       "          [ 216],\n",
       "          [ 633],\n",
       "          [ 500],\n",
       "          [ 955],\n",
       "          [1175],\n",
       "          [  34],\n",
       "          [ 771],\n",
       "          [  13],\n",
       "          [  25],\n",
       "          [ 918],\n",
       "          [ 191],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1]],\n",
       " \n",
       "         [[ 191],\n",
       "          [  13],\n",
       "          [ 500],\n",
       "          [  13],\n",
       "          [ 216],\n",
       "          [ 633],\n",
       "          [ 500],\n",
       "          [ 955],\n",
       "          [1175],\n",
       "          [  34],\n",
       "          [ 771],\n",
       "          [  13],\n",
       "          [  25],\n",
       "          [ 918],\n",
       "          [ 191],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1]],\n",
       " \n",
       "         [[ 191],\n",
       "          [  13],\n",
       "          [ 500],\n",
       "          [  13],\n",
       "          [ 216],\n",
       "          [ 633],\n",
       "          [ 500],\n",
       "          [ 955],\n",
       "          [1175],\n",
       "          [  34],\n",
       "          [ 771],\n",
       "          [  13],\n",
       "          [  25],\n",
       "          [ 918],\n",
       "          [ 191],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1]],\n",
       " \n",
       "         [[ 191],\n",
       "          [  13],\n",
       "          [ 500],\n",
       "          [  13],\n",
       "          [ 216],\n",
       "          [ 633],\n",
       "          [ 500],\n",
       "          [ 955],\n",
       "          [1175],\n",
       "          [  34],\n",
       "          [ 771],\n",
       "          [  13],\n",
       "          [  25],\n",
       "          [ 918],\n",
       "          [ 191],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1]],\n",
       " \n",
       "         [[ 191],\n",
       "          [  13],\n",
       "          [ 500],\n",
       "          [  13],\n",
       "          [ 216],\n",
       "          [ 633],\n",
       "          [ 500],\n",
       "          [ 955],\n",
       "          [1175],\n",
       "          [  34],\n",
       "          [ 771],\n",
       "          [  13],\n",
       "          [  25],\n",
       "          [ 918],\n",
       "          [ 191],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1]],\n",
       " \n",
       "         [[ 191],\n",
       "          [  13],\n",
       "          [ 500],\n",
       "          [  13],\n",
       "          [ 216],\n",
       "          [ 633],\n",
       "          [ 500],\n",
       "          [ 955],\n",
       "          [1175],\n",
       "          [  34],\n",
       "          [ 771],\n",
       "          [  13],\n",
       "          [  25],\n",
       "          [ 918],\n",
       "          [ 191],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1]],\n",
       " \n",
       "         [[ 191],\n",
       "          [  13],\n",
       "          [ 500],\n",
       "          [  13],\n",
       "          [ 216],\n",
       "          [ 633],\n",
       "          [ 500],\n",
       "          [ 955],\n",
       "          [1175],\n",
       "          [  34],\n",
       "          [ 771],\n",
       "          [  13],\n",
       "          [  25],\n",
       "          [ 918],\n",
       "          [ 191],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1],\n",
       "          [   1]]]),\n",
       " 'his_mask': tensor([[[False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True]],\n",
       " \n",
       "         [[False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True]],\n",
       " \n",
       "         [[False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True]],\n",
       " \n",
       "         [[False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True]],\n",
       " \n",
       "         [[False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True]],\n",
       " \n",
       "         [[False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True]],\n",
       " \n",
       "         [[False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True]],\n",
       " \n",
       "         [[False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True]],\n",
       " \n",
       "         [[False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True]],\n",
       " \n",
       "         [[False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [False],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True],\n",
       "          [ True]]]),\n",
       " 'labels': tensor([[0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]])}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([10, 5, 20]), torch.Size([10, 1, 20]))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "a['candidate_title_pad'].shape, b['candidate_title_pad'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tailor Data to demo size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tailor 2000 impressions from MINDsmall_train to form MINDdemo_train\n",
    "tailorData('/home/peitian_zhang/Data/MIND/MINDsmall_train/behaviors.tsv',2000)\n",
    "\n",
    "tailorData('/home/peitian_zhang/Data/MIND/MINDsmall_dev/behaviors.tsv',500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze MIND Datasets\n",
    "- average title length\n",
    "- average abstract length\n",
    "- average history length\n",
    "- average impression capacity\n",
    "- count of history exceeding 50\n",
    "- count of empty history\n",
    "- count of multi-clicked impressions "
   ]
  },
  {
   "source": [
    "analyse(hparams)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## The rest is for developing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "\n",
    "hparams = {\n",
    "    'npratio':4,\n",
    "    'mode':'train',\n",
    "    'scale':'demo',\n",
    "    'batch_size':2,\n",
    "    'his_size':50,\n",
    "    'title_size':15,\n",
    "    'abs_size':20,\n",
    "    'device':'cpu',\n",
    "    'attrs': ['title'],\n",
    "    'k': 20,\n",
    "    'validate':False,\n",
    "    'onehot':False\n",
    "}\n",
    "# torch.cuda.set_device(hparams['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from torch.utils.data import Dataset\n",
    "from utils.utils import newsample, getId2idx, tokenize, getVocab\n",
    "\n",
    "class MIND(Dataset):\n",
    "    \"\"\" Map Style Dataset for MIND, return positive samples with negative sampling when training, or return each sample when developing.\n",
    "\n",
    "    Args:\n",
    "        hparams(dict): pre-defined dictionary of hyper parameters\n",
    "        news_file(str): path of news_file\n",
    "        behaviors_file(str): path of behaviors_file\n",
    "        shuffle(bool): whether to shuffle the order of impressions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hparams, news_file, behaviors_file, shuffle_pos=False, validate=False):\n",
    "        # initiate the whole iterator\n",
    "        self.npratio = hparams['npratio']\n",
    "        self.shuffle_pos = shuffle_pos\n",
    "\n",
    "        self.news_file = news_file\n",
    "        self.behaviors_file = behaviors_file\n",
    "        self.col_spliter = '\\t'\n",
    "        self.batch_size = hparams['batch_size']\n",
    "        self.title_size = hparams['title_size']\n",
    "        self.abs_size = hparams['abs_size']\n",
    "        self.his_size = hparams['his_size']\n",
    "\n",
    "        self.onehot = hparams['onehot']\n",
    "\n",
    "        if 'k' in hparams:\n",
    "            self.k = hparams['k']\n",
    "\n",
    "        self.mode = re.search(\n",
    "            '{}_(.*)/'.format(hparams['scale']), news_file).group(1)\n",
    "\n",
    "        # there are only two types of vocabulary\n",
    "        self.vocab = getVocab('data/dictionaries/vocab_whole.pkl')\n",
    "\n",
    "        self.nid2index = getId2idx(\n",
    "            'data/dictionaries/nid2idx_{}_{}.json'.format(hparams['scale'], self.mode))\n",
    "        self.uid2index = getId2idx(\n",
    "            'data/dictionaries/uid2idx_{}.json'.format(hparams['scale']))\n",
    "        self.vert2onehot = getId2idx(\n",
    "            'data/dictionaries/vert2onehot.json'\n",
    "        )\n",
    "        self.subvert2onehot = getId2idx(\n",
    "            'data/dictionaries/subvert2onehot.json'\n",
    "        )\n",
    "\n",
    "        if validate:\n",
    "            self.mode = 'dev'\n",
    "\n",
    "        self.init_news()\n",
    "        self.init_behaviors()\n",
    "\n",
    "    def init_news(self):\n",
    "        \"\"\"\n",
    "            init news information given news file, such as news_title_array.\n",
    "        \"\"\"\n",
    "\n",
    "        # VERY IMPORTANT!!! FIXME\n",
    "        # The nid2idx dictionary must follow the original order of news in news.tsv\n",
    "\n",
    "        titles = [[1]*self.title_size]\n",
    "        title_pad = [[self.title_size]]\n",
    "        abstracts = [[1]*self.abs_size]\n",
    "        abs_pad = [[self.abs_size]]\n",
    "\n",
    "        # pure text of the title\n",
    "        # titles = [['hello MIND']]\n",
    "        categories = [[1]]\n",
    "        subcategories = [[1]]\n",
    "\n",
    "        with open(self.news_file, \"r\", encoding='utf-8') as rd:\n",
    "            for idx in rd:\n",
    "                nid, vert, subvert, title, ab, url, _, _ = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "\n",
    "                title_token = tokenize(title, self.vocab)\n",
    "                titles.append(title_token[:self.title_size] + [1] * (self.title_size - len(title_token)))\n",
    "                title_pad.append([max(self.title_size - len(title_token), 0)])\n",
    "\n",
    "                abs_token = tokenize(ab, self.vocab)\n",
    "                abstracts.append(abs_token[:self.abs_size] + [1] * (self.abs_size - len(abs_token)))\n",
    "                abs_pad.append([max(self.abs_size - len(abs_token), 0)])\n",
    "\n",
    "                categories.append(tokenize(vert, self.vocab))\n",
    "                subcategories.append(tokenize(subvert, self.vocab))\n",
    "\n",
    "        # self.titles = titles\n",
    "        self.news_title_array = np.asarray(titles)\n",
    "        self.title_pad = np.asarray(title_pad)\n",
    "        self.abs_array = np.asarray(abstracts)\n",
    "        self.abs_pad = np.asarray(abs_pad)\n",
    "        self.vert_array = np.asarray(categories)\n",
    "        self.subvert_array = np.asarray(subcategories)\n",
    "\n",
    "    def init_behaviors(self):\n",
    "        \"\"\"\n",
    "            init behavior logs given behaviors file.\n",
    "        \"\"\"\n",
    "        # list of list of history news index\n",
    "        self.histories = []\n",
    "        # list of user index\n",
    "        self.uindexes = []\n",
    "        # list of list of history padding length\n",
    "        self.his_pad = []\n",
    "        # list of impression indexes\n",
    "        # self.impr_indexes = []\n",
    "\n",
    "        # only store positive behavior\n",
    "        if self.mode == 'train':\n",
    "            # list of list of clicked candidate news index along with its impression index\n",
    "            self.imprs = []\n",
    "            # dictionary of list of unclicked candidate news index\n",
    "            self.negtives = {}\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    impr_index, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "                    # important to subtract 1 because all list related to behaviors start from 0\n",
    "                    impr_index = int(impr_index) - 1\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    if self.k:\n",
    "                        # guarantee there are at least k history not masked\n",
    "                        self.his_pad.append(\n",
    "                            min(max(self.his_size - len(history), 0), self.his_size - self.k))\n",
    "                    else:\n",
    "                        self.his_pad.append(max(self.his_size - len(history), 0))\n",
    "\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.his_size] + [0] * (self.his_size - len(history))\n",
    "                    impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
    "                    labels = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store negative samples of each impression\n",
    "                    negatives = []\n",
    "\n",
    "                    for news, label in zip(impr_news, labels):\n",
    "                        if label == 1:\n",
    "                            self.imprs.append((impr_index, news))\n",
    "                        else:\n",
    "                            negatives.append(news)\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    self.histories.append(history)\n",
    "                    self.negtives[impr_index] = negatives\n",
    "                    self.uindexes.append(uindex)\n",
    "\n",
    "        # store every behaviors\n",
    "        elif self.mode == 'dev':\n",
    "            # list of every candidate news index along with its impression index and label\n",
    "            self.imprs = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    impr_index, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "                    impr_index = int(impr_index) - 1\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    if self.k:\n",
    "                        # guarantee there are at least k history not masked\n",
    "                        self.his_pad.append(\n",
    "                            min(max(self.his_size - len(history), 0), self.his_size - self.k))\n",
    "                    else:\n",
    "                        self.his_pad.append(max(self.his_size - len(history), 0))\n",
    "\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.his_size] + [0] * (self.his_size - len(history))\n",
    "                    impr_news = [self.nid2index[i.split(\"-\")[0]] for i in impr.split()]\n",
    "                    labels = [int(i.split(\"-\")[1]) for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store every impression\n",
    "                    for news, label in zip(impr_news, labels):\n",
    "                        self.imprs.append((impr_index, news, label))\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    self.histories.append(history)\n",
    "                    self.uindexes.append(uindex)\n",
    "\n",
    "        # store every behaviors\n",
    "        elif self.mode == 'test':\n",
    "            # list of every candidate news index along with its impression index and label\n",
    "            self.imprs = []\n",
    "\n",
    "            with open(self.behaviors_file, \"r\", encoding='utf-8') as rd:\n",
    "                for idx in rd:\n",
    "                    impr_index, uid, time, history, impr = idx.strip(\"\\n\").split(self.col_spliter)\n",
    "                    impr_index = int(impr_index) - 1\n",
    "\n",
    "                    history = [self.nid2index[i] for i in history.split()]\n",
    "                    if self.k:\n",
    "                        # guarantee there are at least k history not masked\n",
    "                        self.his_pad.append(\n",
    "                            min(max(self.his_size - len(history), 0), self.his_size - self.k))\n",
    "                    else:\n",
    "                        self.his_pad.append(max(self.his_size - len(history), 0))\n",
    "\n",
    "                    # tailor user's history or pad 0\n",
    "                    history = history[:self.his_size] + [0] * (self.his_size - len(history))\n",
    "                    impr_news = [self.nid2index[i] for i in impr.split()]\n",
    "                    # user will always in uid2index\n",
    "                    uindex = self.uid2index[uid]\n",
    "\n",
    "                    # store every impression\n",
    "                    for news in impr_news:\n",
    "                        self.imprs.append((impr_index, news))\n",
    "\n",
    "                    # 1 impression correspond to 1 of each of the following properties\n",
    "                    self.histories.append(history)\n",
    "                    self.uindexes.append(uindex)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "            return length of the whole dataset\n",
    "        \"\"\"\n",
    "        return len(self.imprs)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \"\"\" return data\n",
    "        Args:\n",
    "            index: the index for stored impression\n",
    "\n",
    "        Returns:\n",
    "            back_dic: dictionary of data slice\n",
    "        \"\"\"\n",
    "\n",
    "        impr = self.imprs[index] # (impression_index, news_index)\n",
    "        impr_index = impr[0]\n",
    "        impr_news = impr[1]\n",
    "\n",
    "        user_index = [self.uindexes[impr_index]]\n",
    "\n",
    "        # each time called to return positive one sample and its negative samples\n",
    "        if self.mode == 'train':\n",
    "            # user's unclicked news in the same impression\n",
    "            negs = self.negtives[impr_index]\n",
    "            neg_list, neg_pad = newsample(negs, self.npratio)\n",
    "\n",
    "            cdd_ids = np.asarray([impr_news] + neg_list)\n",
    "            label = np.asarray([1] + [0] * self.npratio)\n",
    "\n",
    "            if self.shuffle_pos:\n",
    "                s = np.arange(0, len(label), 1)\n",
    "                np.random.shuffle(s)\n",
    "                cdd_ids = np.asarray(cdd_ids)[s]\n",
    "                label = np.asarray(label)[s]\n",
    "\n",
    "            # true means the corresponding history news is padded\n",
    "            his_mask = np.zeros((self.his_size, 1), dtype=bool)\n",
    "            his_ids = self.histories[impr_index]\n",
    "\n",
    "            # in case the user has no history records, do not mask\n",
    "            if self.his_pad[impr_index] == self.his_size or self.his_pad[impr_index] == 0:\n",
    "                his_mask = his_mask\n",
    "            else:\n",
    "                his_mask[-self.his_pad[impr_index]:] = [True]\n",
    "\n",
    "            # pad in candidate\n",
    "            # candidate_mask = [1] * neg_pad + [0] * (self.npratio + 1 - neg_pad)\n",
    "\n",
    "            # pad in title\n",
    "            candidate_title_pad = [(self.title_size - i[0])*[1] + i[0]*[0] for i in self.title_pad[cdd_ids]]\n",
    "            clicked_title_pad = [(self.title_size - i[0])*[1] + i[0]*[0] for i in self.title_pad[his_ids]]\n",
    "            candidate_abs_pad = [(self.abs_size - i[0])*[1] + i[0]*[0] for i in self.abs_pad[cdd_ids]]\n",
    "            clicked_abs_pad = [(self.abs_size - i[0])*[1] + i[0]*[0] for i in self.abs_pad[his_ids]]\n",
    "\n",
    "            candidate_title_index = self.news_title_array[cdd_ids]\n",
    "            clicked_title_index = self.news_title_array[his_ids]\n",
    "            candidate_abs_index = self.abs_array[cdd_ids]\n",
    "            clicked_abs_index = self.abs_array[his_ids]\n",
    "            candidate_vert_index = self.vert_array[cdd_ids]\n",
    "            clicked_vert_index = self.vert_array[his_ids]\n",
    "            candidate_subvert_index = self.subvert_array[cdd_ids]\n",
    "            clicked_subvert_index = self.subvert_array[his_ids]\n",
    "\n",
    "            back_dic = {\n",
    "                \"user_index\": np.asarray(user_index),\n",
    "                # \"cdd_mask\": np.asarray(neg_pad),\n",
    "                'cdd_id': cdd_ids,\n",
    "                \"candidate_title\": candidate_title_index,\n",
    "                \"candidate_title_pad\": np.asarray(candidate_title_pad),\n",
    "                \"candidate_abs\": candidate_abs_index,\n",
    "                \"candidate_abs_pad\": np.asarray(candidate_abs_pad),\n",
    "                \"candidate_vert\": candidate_vert_index,\n",
    "                \"candidate_subvert\": candidate_subvert_index,\n",
    "                'his_id': np.asarray(his_ids),\n",
    "                \"clicked_title\": clicked_title_index,\n",
    "                \"clicked_title_pad\": np.asarray(clicked_title_pad),\n",
    "                \"clicked_abs\": clicked_abs_index,\n",
    "                \"clicked_abs_pad\": np.asarray(clicked_abs_pad),\n",
    "                \"clicked_vert\": clicked_vert_index,\n",
    "                \"clicked_subvert\": clicked_subvert_index,\n",
    "                \"his_mask\": his_mask,\n",
    "                \"labels\": label\n",
    "            }\n",
    "\n",
    "            if self.onehot:\n",
    "                candidate_vert_onehot = [self.vert2onehot[str(i[0])] for i in candidate_vert_index]\n",
    "                clicked_vert_onehot = [self.vert2onehot[str(i[0])] for i in clicked_vert_index]\n",
    "\n",
    "                candidate_subvert_onehot = [self.subvert2onehot[str(i[0])] for i in candidate_subvert_index]\n",
    "                clicked_subvert_onehot = [self.subvert2onehot[str(i[0])] for i in clicked_subvert_index]\n",
    "\n",
    "                back_dic['candidate_vert_onehot'] = np.asarray(candidate_vert_onehot)\n",
    "                back_dic['clicked_vert_onehot'] = np.asarray(clicked_vert_onehot)\n",
    "                back_dic['candidate_subvert_onehot'] = np.asarray(candidate_subvert_onehot)\n",
    "                back_dic['clicked_subvert_onehot'] = np.asarray(clicked_subvert_onehot)\n",
    "\n",
    "            return back_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hparams['mode'] = 'dev'\n",
    "hparams['onehot'] = True\n",
    "path='/home/peitian_zhang/Data/MIND'\n",
    "news_file = path+'/MIND'+hparams['scale']+'_{}/news.tsv'.format(hparams['mode'])\n",
    "behavior_file = path+'/MIND' + hparams['scale']+'_{}/behaviors.tsv'.format(hparams['mode'])\n",
    "dataset = MIND(hparams=hparams, news_file=news_file,behaviors_file=behavior_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__getitem__(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2news = {v:k for k,v in dataset.nid2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2news[13998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.vocab['mmaufc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset, batch_size=5)\n",
    "list(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert2onehot = getId2idx(\n",
    "    'data/dictionaries/vert2onehot.json'\n",
    ")\n",
    "subvert2onehot = getId2idx(\n",
    "    'data/dictionaries/subvert2onehot.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvert2onehot['1'] = [0]*len(subvert2onehot['2513'])\n",
    "del subvert2onehot['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert2onehot['1'] = [0]*len(vert2onehot['138'])\n",
    "del vert2onehot['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert2onehot['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['candidate_vert_onehot'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(dataset, batch_size=10, pin_memory=False, num_workers=0, drop_last=False, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(loader_train))['candidate_vert'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
    "\n",
    "\n",
    "def news_token_generator(news_file_list, tokenizer, attrs):\n",
    "    ''' merge and deduplicate training news and testing news then iterate, collect attrs into a single sentence and generate it\n",
    "\n",
    "    Args:\n",
    "        tokenizer: torchtext.data.utils.tokenizer\n",
    "        attrs: list of attrs to be collected and yielded\n",
    "    Returns:\n",
    "        a generator over attrs in news\n",
    "    '''\n",
    "    news_df_list = []\n",
    "    for f in news_file_list:\n",
    "        news_df_list.append(pd.read_table(f, index_col=None, names=[\n",
    "                            'newsID', 'category', 'subcategory', 'title', 'abstract', 'url', 'entity_title', 'entity_abstract'], quoting=3))\n",
    "\n",
    "    news_df = pd.concat(news_df_list).drop_duplicates()\n",
    "    news_iterator = news_df.iterrows()\n",
    "\n",
    "    for _, i in news_iterator:\n",
    "        content = []\n",
    "        for attr in attrs:\n",
    "            content.append(i[attr])\n",
    "\n",
    "        yield tokenizer(' '.join(content))\n",
    "\n",
    "\n",
    "def constructVocab(news_file_list, attrs):\n",
    "    \"\"\"\n",
    "        Build field using torchtext for tokenization\n",
    "\n",
    "    Returns:\n",
    "        torchtext.vocabulary\n",
    "    \"\"\"\n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        news_token_generator(news_file_list, tokenizer, attrs))\n",
    "\n",
    "    output = open(\n",
    "        'data/dictionaries/vocab_{}.pkl'.format(','.join(attrs)), 'wb')\n",
    "    pickle.dump(vocab, output)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "attrs = ['title','category','subcategory']\n",
    "path= '/home/peitian_zhang/Data/MIND'\n",
    "scale = 'large'\n",
    "news_file_list = [path + '/MIND{}_train/news.tsv'.format(scale), path + '/MIND{}_dev/news.tsv'.format(scale), path + '/MIND{}_test/news.tsv'.format(scale)]\n",
    "constructVocab(news_file_list, attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subvert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in subvert:\n",
    "    if (tokenize(i, dataset.vocab)) == [0]:\n",
    "        print(\"fuck\")\n",
    "    if dataset.vocab[i] == 0:\n",
    "        print(\"fuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert,subvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['basketball_nba_videos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import getVocab,tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.itos[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvert2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.itos[771]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vert2onehot = {}\n",
    "for k,v in vert2idx.items():\n",
    "    a = np.zeros((len(vert2idx)))\n",
    "    index = np.asarray([v])\n",
    "    a[index] = 1\n",
    "    vert2onehot[int(k)] = a.tolist()\n",
    "vert2onehot[1] = [0]*len(vert2onehot[30])\n",
    "\n",
    "subvert2onehot = {}\n",
    "for k,v in subvert2idx.items():\n",
    "    a = np.zeros((len(subvert2idx)))\n",
    "    index = np.asarray([v])\n",
    "    a[index] = 1\n",
    "    subvert2onehot[int(k)] = a.tolist()\n",
    "subvert2onehot[1] = [0]*len(subvert2onehot[771])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvert2onehot[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(vert2onehot, open('data/dictionaries/vert2onehot.json','w'),ensure_ascii=False)\n",
    "json.dump(subvert2onehot, open('data/dictionaries/subvert2onehot.json','w'),ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}